{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ue5hxxkdAQJg"
   },
   "source": [
    "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
    "\n",
    "\n",
    "# Procesamiento de lenguaje natural\n",
    "## Bot con NLTK utilizando un corpus de wikipedia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "kCED1hh-Ioyf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\apguz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\apguz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\apguz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import string\n",
    "import random\n",
    "import re\n",
    "import urllib.request\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Para leer y parsear el texto en HTML de wikipedia\n",
    "import bs4 as bs\n",
    "\n",
    "import nltk\n",
    "# Descargar el diccionario\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DMOa4JPSCJ29"
   },
   "source": [
    "### Datos\n",
    "Se consumira los datos del artículo de wikipedia sobre el \"memex\" en ingles.\n",
    "\n",
    "El memex fue una dispositivo nunca desarrollado (o por lo menos nunca desarrollado por Vannevar Bush) que basicamente era un consultor de textos y apuntes usando microfilms. Un poco la idea era la misma que con este bot: consultar textos basado en palabras claves.\n",
    "\n",
    "Contexto: https://proyectoidis.org/memex/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "RIO7b8GjAC17"
   },
   "outputs": [],
   "source": [
    "raw_html = urllib.request.urlopen('https://en.wikipedia.org/wiki/Memex')\n",
    "raw_html = raw_html.read()\n",
    "\n",
    "article_html = bs.BeautifulSoup(raw_html, 'lxml')\n",
    "\n",
    "article_paragraphs = article_html.find_all('p')\n",
    "\n",
    "article_text = ''\n",
    "\n",
    "for para in article_paragraphs:\n",
    "    article_text += para.text\n",
    "\n",
    "article_text = article_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "pUH30a1_rOkS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'memex is a hypothetical electromechanical device for interacting with microform documents and described in vannevar bush\\'s 1945 article \"as we may think\". bush envisioned the memex as a device in which individuals would compress and store all of their books, records, and communications, \"mechanized so that it may be consulted with exceeding speed and flexibility\". the individual was supposed to use the memex as an automatic personal filing system, making the memex \"an enlarged intimate supplement to his memory\".[1] the name memex is a portmanteau of memory and expansion.\\nthe concept of the memex influenced the development of early hypertext systems, eventually leading to the creation of the world wide web, and personal knowledge base software.[2] the hypothetical implementation depicted by bush for the purpose of concrete illustration was based upon a document bookmark list of static microfilm pages and lacked a true hypertext system, where parts of pages would have internal structure beyond the common textual format. \\nin \"as we may think\", vannevar bush describes a memex as an electromechanical device enabling individuals to develop and read a large self-contained research library, create and follow associative trails of links and personal annotations, and recall these trails at any time to share them with other researchers. this device would closely mimic the associative processes of the human mind, but it would be gifted with permanent recollection. as bush writes, \"thus science may implement the ways in which man produces, stores, and consults the record of the race\".[3]\\nthe technology used would have been a combination of electromechanical controls and microfilm cameras and readers, all integrated into a large desk. most of the microfilm library would have been contained within the desk, but the user could add or remove microfilm reels at will. a memex would hypothetically read and write content on these microfilm reels, using electric photocells to read coded symbols recorded next to individual microfilm frames while the reels spun at high speed, stopping on command. the coded symbols would enable the memex to index, search, and link content to create and follow associative trails.\\nthe top of the desk would have slanting translucent screens on which material could be projected for convenient reading. the top of the memex would have a transparent platen. when a longhand note, photograph, memoranda, or other things were placed on the platen, the depression of a lever would cause the item to be photographed onto the next blank space in a section of the memex film.\\naccording to bush, memex could become \"a sort of mechanized private file and library\".[4] the memex device as described by bush \"would use microfilm storage, dry photography, and analog computing to give postwar scholars access to a huge, indexed repository of knowledge any section of which could be called up with a few keystrokes.\"[5]\\nan associative trail as conceived by bush would be a way to create a new linear sequence of microfilm frames across any arbitrary sequence of microfilm frames by creating a chained sequence of links in the way just described, along with personal comments and side trails. at the time, bush saw the current ways of indexing information as limiting and instead proposed a way to store information that was analogous to the mental association of the human brain: storing information with the capability of easy access at a later time using certain cues (in this case, a series of numbers as a code to retrieve data).[6]\\naccording to bush, the memex would have features other than linking. the user could record new information on microfilm, by taking photos from paper or from a touch-sensitive translucent screen. a user could \"...insert a comment of his own, either linking it into the main trail or joining it by a side trail to a particular item. ...thus he builds a trail of his interest through the maze of materials available to him.\"[7] a user could also create a copy of an interesting trail (containing references and personal annotations) and \"...pass it to his friend for insertion in his own memex, there to be linked into the more general trail.\"[7]\\nin september 1945, life magazine published an illustration by alfred d. crimi showing the \"memex desk\". according to life magazine, the memex desk \"would instantly bring files and material on an subject to the operator\\'s fingertips\". the mechanical core of the desk would also include \"a mechanism which automatically photographs longhand notes, pictures and letters, the file them in the desk for future reference.\"[8]\\nbush\\'s 1945 \"as we may think\" idea for the memex extended far beyond a mechanism that might augment the research of one individual working in isolation. in bush\\'s idea, the ability to connect, annotate, and share both published works and personal trails would profoundly change the process by which the \"world\\'s record\" is created and used:\\nwholly new forms of encyclopedias will appear, ready-made with a mesh of associative trails running through them, ready to be dropped into the memex and there amplified. the lawyer has at his touch the associated opinions and decisions of his whole experience, and of the experience of friends and authorities. the patent attorney has on call the millions of issued patents, with familiar trails to every point of his client\\'s interest. the physician, puzzled by a patient\\'s reactions, strikes the trail established in studying an earlier similar case, and runs rapidly through analogous case histories, with side references to the classics for the pertinent anatomy and histology. ...\\nthe historian, with a vast chronological account of a people, parallels it with a skip trail that stops only on the salient items and can follow at any time contemporary trails which lead him all over civilization at a particular epoch. there is a new profession of trailblazers, those who find delight in the task of establishing useful trails through the enormous mass of the common record. the inheritance from the master becomes, not only his additions to the world\\'s record but for his disciples the entire scaffolding by which they were erected. — as we may think\\nbush said of his \"as we may think\" memex device that \"technical difficulties of all sorts have been ignored,\" but that, \"also ignored are means as yet unknown which may come any day to accelerate technical progress as violently as did the advent of the thermionic tube.\"[3] michael buckland concluded that bush\\'s 1945 vision for an information retrieval machine is unhistorically viewed in relation to the subsequent development of electronic computer technology. buckland studied the historical background of information retrieval in and before 1939 because the memex was based on bush\\'s work during 1938–1940 in building a photoelectric microfilm selector, an electronic retrieval technology invented by emanuel goldberg for zeiss ikon in the 1920s. according to buckland, the legacy of bush is twofold: a significant engineering achievement in building a rapid prototype microfilm selector, and \"a speculative article\" which through \"the social prestige of its author, has had an immediate and lasting effect in stimulating others.\"[9]\\nthe pioneer of human–computer interaction douglas engelbart was inspired by bush\\'s proposal for a co-evolution between humans and machines.[10] in a 1999 publication, engelbart recollects that reading \"as we may think\" in 1945 infected him with the idea of building a mechanism that could navigate and extend the pool of human knowledge.[11] around 1961, engelbart re-read bush\\'s article, and from 1962 onward engelbart developed a series of technical designs.[12] engelbart updated the memex microfilm storage desk and thereby arrived at a pioneering vision for a personal computer connected to an electronic visual display and a mouse pointing device.[13] in 1962, engelbart sent bush a draft article for comment, bush never replied. the article was published in 1963 under the title \"a conceptual framework for the augmentation of man\\'s intellect\".[14]\\nin 1965, j. c. r. licklider dedicated his book \"libraries of the future\" to bush. licklider wrote that he had often heard of the memex and \"trails of reference\", even before he had read \"as we may think\".[15] also in 1965, ted nelson coined the word hypertext in a paper that quoted bush\\'s memex idea at length.[16] in 1968, nelson collaborated with andries van dam to implement the hypertext editing system (hes).[17] in his 1987 book entitled \"literary machines\", nelson defined hypertext as \"non-sequential writing with reader-controlled links\".[18] in 2000, tim berners-lee published a statement, acknowledging the influence of hypertext, the work of engelbart and bush\\'s \"as we may think\" on the development of the world wide web.[15] in 2003, microsoft promoted a life-logging research project under the name mylifebits as an attempt to fulfill bush\\'s memex vision.[19]\\nin 1959, vannevar bush described an improved \"memex ii\".[20] in the manuscript draft of \"memex ii\" he wrote, \"professional societies will no longer print papers...\" and states that individuals will either order sets of papers to come on tape – complete with photographs and diagrams – or download \\'facsimiles\\' by telephone. each society would maintain a \\'master memex\\' containing all papers, references, tables \"intimately interconnected by trails, so that one may follow a detailed matter from paper to paper, going back through the classics, recording criticism in the margins.\"[21]\\nin 1967, vannevar bush published a retrospective article entitled \"memex revisited\"[22]in his book science is not enough. published 22 years after his initial conception of the memex, bush details the various technological advancements that have made his vision a possibility. specifically, bush cites photocells, transistors, cathode ray tubes, magnetic and videotape, \"high-speed electric circuits\", and \"miniaturization of solid-state devices\" such as the tv and radio. the article claims that magnetic tape would be central to the creation of a modern memex device. the erasable quality of the tape is of special significance, as this would allow for modification of information stored in the proposed memex.[22]\\nin the 1967 article \"memex revisited\", bush stresses the continued importance of supplementing \"how creative men think\" and relates that the systems for indexing data are still insufficient and rely too much on linear pathways rather than the association-based system of the human brain. bush writes that a machine with the \"speed and flexibility\" of the brain is not attainable, but improvements could be made in regard to the capacity to obtain informational \"permanence and clarity\".[22]\\nbush also relates that, unlike digital technology, memex would be of no significant aid to business or profitable ventures, and as a consequence, its development would occur only long after the mechanization of libraries and the introduction of what he describes as the specialized \"group machine\", which would be useful for the sharing of ideas in fields such as medicine. furthermore, although bush discusses the compressional ability and rapidity so key to modern machines, he relates that speed will not be an integral part of memex, stating that a tenth of a second would be an acceptable interval for its data retrieval, rather than the billionths of a second that modern computers are capable of. \"for memex,\" he writes, \"the problem is not swift access, but selective access\". bush states that although the code-reading and potential linking capabilities of the rapid selector would be key to the creation of memex, there is still an issue of enabling \"moderately rapid access to really large memory storage\". there is an issue concerning selection, bush conveys, and despite the fact that improvements have been made in the speed of digital selection, according to bush, \"selection, in the broad sense, is still a stone adze in the hands of the cabinetmaker\". bush goes on to discuss the record-making process and how memex could incorporate systems of voice-control and user-propagated learning.[22]he proposes a machine that could respond to \"simple remarks\" as well as build trails[22]based on its user\\'s \"habits of association,\" as belinda barnet described them in \"the technical evolution of vannevar bush\\'s memex.\" barnet also makes the distinction between the idea of a constructive memex and the \"permanent trails\" described in as we may think, and attributes bush\\'s machine learning concepts to claude shannon\\'s mechanical mouse and work with \"feedback and machine learning\".[23]\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Demos un vistazo\n",
    "article_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "BtGLJjt6rQhK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de caracteres en la nota: 12692\n"
     ]
    }
   ],
   "source": [
    "print(\"Cantidad de caracteres en la nota:\", len(article_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FVHxBRNzCMOS"
   },
   "source": [
    "### 2 - Preprocesamiento\n",
    "- Remover caracteres especiales\n",
    "- Quitar espacios o saltos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "HnEUTD1Erl1N"
   },
   "outputs": [],
   "source": [
    "#sustituir los números entre corchetes por un espacio en blanco\n",
    "text = re.sub(r'\\[[0-9]*\\]', ' ', article_text)\n",
    "#sustituir más de un caracter de espacio, salto de línea o tabulación\n",
    "text = re.sub(r'\\s+', ' ', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "g7ycrAMYrn66"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'memex is a hypothetical electromechanical device for interacting with microform documents and described in vannevar bush\\'s 1945 article \"as we may think\". bush envisioned the memex as a device in which individuals would compress and store all of their books, records, and communications, \"mechanized so that it may be consulted with exceeding speed and flexibility\". the individual was supposed to use the memex as an automatic personal filing system, making the memex \"an enlarged intimate supplement to his memory\". the name memex is a portmanteau of memory and expansion. the concept of the memex influenced the development of early hypertext systems, eventually leading to the creation of the world wide web, and personal knowledge base software. the hypothetical implementation depicted by bush for the purpose of concrete illustration was based upon a document bookmark list of static microfilm pages and lacked a true hypertext system, where parts of pages would have internal structure beyond the common textual format. in \"as we may think\", vannevar bush describes a memex as an electromechanical device enabling individuals to develop and read a large self-contained research library, create and follow associative trails of links and personal annotations, and recall these trails at any time to share them with other researchers. this device would closely mimic the associative processes of the human mind, but it would be gifted with permanent recollection. as bush writes, \"thus science may implement the ways in which man produces, stores, and consults the record of the race\". the technology used would have been a combination of electromechanical controls and microfilm cameras and readers, all integrated into a large desk. most of the microfilm library would have been contained within the desk, but the user could add or remove microfilm reels at will. a memex would hypothetically read and write content on these microfilm reels, using electric photocells to read coded symbols recorded next to individual microfilm frames while the reels spun at high speed, stopping on command. the coded symbols would enable the memex to index, search, and link content to create and follow associative trails. the top of the desk would have slanting translucent screens on which material could be projected for convenient reading. the top of the memex would have a transparent platen. when a longhand note, photograph, memoranda, or other things were placed on the platen, the depression of a lever would cause the item to be photographed onto the next blank space in a section of the memex film. according to bush, memex could become \"a sort of mechanized private file and library\". the memex device as described by bush \"would use microfilm storage, dry photography, and analog computing to give postwar scholars access to a huge, indexed repository of knowledge any section of which could be called up with a few keystrokes.\" an associative trail as conceived by bush would be a way to create a new linear sequence of microfilm frames across any arbitrary sequence of microfilm frames by creating a chained sequence of links in the way just described, along with personal comments and side trails. at the time, bush saw the current ways of indexing information as limiting and instead proposed a way to store information that was analogous to the mental association of the human brain: storing information with the capability of easy access at a later time using certain cues (in this case, a series of numbers as a code to retrieve data). according to bush, the memex would have features other than linking. the user could record new information on microfilm, by taking photos from paper or from a touch-sensitive translucent screen. a user could \"...insert a comment of his own, either linking it into the main trail or joining it by a side trail to a particular item. ...thus he builds a trail of his interest through the maze of materials available to him.\" a user could also create a copy of an interesting trail (containing references and personal annotations) and \"...pass it to his friend for insertion in his own memex, there to be linked into the more general trail.\" in september 1945, life magazine published an illustration by alfred d. crimi showing the \"memex desk\". according to life magazine, the memex desk \"would instantly bring files and material on an subject to the operator\\'s fingertips\". the mechanical core of the desk would also include \"a mechanism which automatically photographs longhand notes, pictures and letters, the file them in the desk for future reference.\" bush\\'s 1945 \"as we may think\" idea for the memex extended far beyond a mechanism that might augment the research of one individual working in isolation. in bush\\'s idea, the ability to connect, annotate, and share both published works and personal trails would profoundly change the process by which the \"world\\'s record\" is created and used: wholly new forms of encyclopedias will appear, ready-made with a mesh of associative trails running through them, ready to be dropped into the memex and there amplified. the lawyer has at his touch the associated opinions and decisions of his whole experience, and of the experience of friends and authorities. the patent attorney has on call the millions of issued patents, with familiar trails to every point of his client\\'s interest. the physician, puzzled by a patient\\'s reactions, strikes the trail established in studying an earlier similar case, and runs rapidly through analogous case histories, with side references to the classics for the pertinent anatomy and histology. ... the historian, with a vast chronological account of a people, parallels it with a skip trail that stops only on the salient items and can follow at any time contemporary trails which lead him all over civilization at a particular epoch. there is a new profession of trailblazers, those who find delight in the task of establishing useful trails through the enormous mass of the common record. the inheritance from the master becomes, not only his additions to the world\\'s record but for his disciples the entire scaffolding by which they were erected. — as we may think bush said of his \"as we may think\" memex device that \"technical difficulties of all sorts have been ignored,\" but that, \"also ignored are means as yet unknown which may come any day to accelerate technical progress as violently as did the advent of the thermionic tube.\" michael buckland concluded that bush\\'s 1945 vision for an information retrieval machine is unhistorically viewed in relation to the subsequent development of electronic computer technology. buckland studied the historical background of information retrieval in and before 1939 because the memex was based on bush\\'s work during 1938–1940 in building a photoelectric microfilm selector, an electronic retrieval technology invented by emanuel goldberg for zeiss ikon in the 1920s. according to buckland, the legacy of bush is twofold: a significant engineering achievement in building a rapid prototype microfilm selector, and \"a speculative article\" which through \"the social prestige of its author, has had an immediate and lasting effect in stimulating others.\" the pioneer of human–computer interaction douglas engelbart was inspired by bush\\'s proposal for a co-evolution between humans and machines. in a 1999 publication, engelbart recollects that reading \"as we may think\" in 1945 infected him with the idea of building a mechanism that could navigate and extend the pool of human knowledge. around 1961, engelbart re-read bush\\'s article, and from 1962 onward engelbart developed a series of technical designs. engelbart updated the memex microfilm storage desk and thereby arrived at a pioneering vision for a personal computer connected to an electronic visual display and a mouse pointing device. in 1962, engelbart sent bush a draft article for comment, bush never replied. the article was published in 1963 under the title \"a conceptual framework for the augmentation of man\\'s intellect\". in 1965, j. c. r. licklider dedicated his book \"libraries of the future\" to bush. licklider wrote that he had often heard of the memex and \"trails of reference\", even before he had read \"as we may think\". also in 1965, ted nelson coined the word hypertext in a paper that quoted bush\\'s memex idea at length. in 1968, nelson collaborated with andries van dam to implement the hypertext editing system (hes). in his 1987 book entitled \"literary machines\", nelson defined hypertext as \"non-sequential writing with reader-controlled links\". in 2000, tim berners-lee published a statement, acknowledging the influence of hypertext, the work of engelbart and bush\\'s \"as we may think\" on the development of the world wide web. in 2003, microsoft promoted a life-logging research project under the name mylifebits as an attempt to fulfill bush\\'s memex vision. in 1959, vannevar bush described an improved \"memex ii\". in the manuscript draft of \"memex ii\" he wrote, \"professional societies will no longer print papers...\" and states that individuals will either order sets of papers to come on tape – complete with photographs and diagrams – or download \\'facsimiles\\' by telephone. each society would maintain a \\'master memex\\' containing all papers, references, tables \"intimately interconnected by trails, so that one may follow a detailed matter from paper to paper, going back through the classics, recording criticism in the margins.\" in 1967, vannevar bush published a retrospective article entitled \"memex revisited\" in his book science is not enough. published 22 years after his initial conception of the memex, bush details the various technological advancements that have made his vision a possibility. specifically, bush cites photocells, transistors, cathode ray tubes, magnetic and videotape, \"high-speed electric circuits\", and \"miniaturization of solid-state devices\" such as the tv and radio. the article claims that magnetic tape would be central to the creation of a modern memex device. the erasable quality of the tape is of special significance, as this would allow for modification of information stored in the proposed memex. in the 1967 article \"memex revisited\", bush stresses the continued importance of supplementing \"how creative men think\" and relates that the systems for indexing data are still insufficient and rely too much on linear pathways rather than the association-based system of the human brain. bush writes that a machine with the \"speed and flexibility\" of the brain is not attainable, but improvements could be made in regard to the capacity to obtain informational \"permanence and clarity\". bush also relates that, unlike digital technology, memex would be of no significant aid to business or profitable ventures, and as a consequence, its development would occur only long after the mechanization of libraries and the introduction of what he describes as the specialized \"group machine\", which would be useful for the sharing of ideas in fields such as medicine. furthermore, although bush discusses the compressional ability and rapidity so key to modern machines, he relates that speed will not be an integral part of memex, stating that a tenth of a second would be an acceptable interval for its data retrieval, rather than the billionths of a second that modern computers are capable of. \"for memex,\" he writes, \"the problem is not swift access, but selective access\". bush states that although the code-reading and potential linking capabilities of the rapid selector would be key to the creation of memex, there is still an issue of enabling \"moderately rapid access to really large memory storage\". there is an issue concerning selection, bush conveys, and despite the fact that improvements have been made in the speed of digital selection, according to bush, \"selection, in the broad sense, is still a stone adze in the hands of the cabinetmaker\". bush goes on to discuss the record-making process and how memex could incorporate systems of voice-control and user-propagated learning. he proposes a machine that could respond to \"simple remarks\" as well as build trails based on its user\\'s \"habits of association,\" as belinda barnet described them in \"the technical evolution of vannevar bush\\'s memex.\" barnet also makes the distinction between the idea of a constructive memex and the \"permanent trails\" described in as we may think, and attributes bush\\'s machine learning concepts to claude shannon\\'s mechanical mouse and work with \"feedback and machine learning\". '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Demos un vistazo\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "PA5F0s4UsMpf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de caracteres en el texto: 12585\n"
     ]
    }
   ],
   "source": [
    "print(\"Cantidad de caracteres en el texto:\", len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DKNcDGcisajf"
   },
   "source": [
    "### 3 - Dividir el texto en sentencias y en palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "reXBOFQ7sdlB"
   },
   "outputs": [],
   "source": [
    "corpus = nltk.sent_tokenize(text)\n",
    "words = nltk.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "J5GloV9fsi6o"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['memex is a hypothetical electromechanical device for interacting with microform documents and described in vannevar bush\\'s 1945 article \"as we may think\".',\n",
       " 'bush envisioned the memex as a device in which individuals would compress and store all of their books, records, and communications, \"mechanized so that it may be consulted with exceeding speed and flexibility\".',\n",
       " 'the individual was supposed to use the memex as an automatic personal filing system, making the memex \"an enlarged intimate supplement to his memory\".',\n",
       " 'the name memex is a portmanteau of memory and expansion.',\n",
       " 'the concept of the memex influenced the development of early hypertext systems, eventually leading to the creation of the world wide web, and personal knowledge base software.',\n",
       " 'the hypothetical implementation depicted by bush for the purpose of concrete illustration was based upon a document bookmark list of static microfilm pages and lacked a true hypertext system, where parts of pages would have internal structure beyond the common textual format.',\n",
       " 'in \"as we may think\", vannevar bush describes a memex as an electromechanical device enabling individuals to develop and read a large self-contained research library, create and follow associative trails of links and personal annotations, and recall these trails at any time to share them with other researchers.',\n",
       " 'this device would closely mimic the associative processes of the human mind, but it would be gifted with permanent recollection.',\n",
       " 'as bush writes, \"thus science may implement the ways in which man produces, stores, and consults the record of the race\".',\n",
       " 'the technology used would have been a combination of electromechanical controls and microfilm cameras and readers, all integrated into a large desk.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Demos un vistazo\n",
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "hmQ7nkvvsi0i"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['memex',\n",
       " 'is',\n",
       " 'a',\n",
       " 'hypothetical',\n",
       " 'electromechanical',\n",
       " 'device',\n",
       " 'for',\n",
       " 'interacting',\n",
       " 'with',\n",
       " 'microform',\n",
       " 'documents',\n",
       " 'and',\n",
       " 'described',\n",
       " 'in',\n",
       " 'vannevar',\n",
       " 'bush',\n",
       " \"'s\",\n",
       " '1945',\n",
       " 'article',\n",
       " '``']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Demos un vistazo\n",
    "words[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "YXPWNkKfEvDZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulario: 2319\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulario:\", len(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NlYKyb3OtDse"
   },
   "source": [
    "### 4 - Funciones de ayuda para limpiar y procesar el input del usuario\n",
    "- Lematizar los tokens de la oración\n",
    "- Quitar símbolos de puntuación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "afPok8pstPOx"
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def perform_lemmatization(tokens):\n",
    "    return [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "punctuation_removal = dict((ord(punctuation), None) for punctuation in string.punctuation)\n",
    "\n",
    "def get_processed_text(document):\n",
    "    # 1 - reduce el texto a mínuscula\n",
    "    # 2 - quitar los simbolos de puntuacion\n",
    "    # 3 - realiza la tokenización\n",
    "    # 4 - realiza la lematización\n",
    "    return perform_lemmatization(nltk.word_tokenize(document.lower().translate(punctuation_removal)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jl8r6d9ZuyR9"
   },
   "source": [
    "### 5 - Utilizar vectores TF-IDF y la similitud coseno construido con el corpus de wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "IRYFHcBfk2Gt"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def generate_response(user_input, corpus):\n",
    "    response = ''\n",
    "    # Sumar al corpus la pregunta del usuario para calcular\n",
    "    # su cercania con otros documentos/sentencias\n",
    "    corpus.append(user_input)\n",
    "\n",
    "    # Crear un vectorizar TFIDF que quite las \"stop words\" del ingles y utilice\n",
    "    # nuestra funcion para obtener los tokens lematizados \"get_processed_text\"\n",
    "    word_vectorizer = TfidfVectorizer(tokenizer=get_processed_text, stop_words='english')\n",
    "\n",
    "    # Crear los vectores a partir del corpus\n",
    "    all_word_vectors = word_vectorizer.fit_transform(corpus)\n",
    "\n",
    "    # Calcular la similitud coseno entre todas los documentos excepto el agregado (el útlimo \"-1\")\n",
    "    # NOTA: con los word embedings veremos más en detalle esta matriz de similitud\n",
    "    similar_vector_values = cosine_similarity(all_word_vectors[-1], all_word_vectors)\n",
    "\n",
    "    # Obtener el índice del vector más cercano a nuestra oración\n",
    "    # --> descartando la similitud contra nuestor vector propio\n",
    "    similar_sentence_number = similar_vector_values.argsort()[0][-2]\n",
    "    matched_vector = similar_vector_values.flatten()\n",
    "    matched_vector.sort()\n",
    "    vector_matched = matched_vector[-2]\n",
    "\n",
    "    if vector_matched == 0:\n",
    "        response = \"I am sorry, I could not understand you\"\n",
    "    else:\n",
    "        response = corpus[similar_sentence_number]\n",
    "    \n",
    "    corpus.remove(user_input)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OK-BuXPBybSp"
   },
   "source": [
    "### 6 - Ensayar el sistema\n",
    "El sistema intentará encontrar la parte del artículo que más se relaciona con nuestro texto de entrada. Sugerencias ensayar:\n",
    "- Vannevar Bush\n",
    "- Memory\n",
    "- Hypertext\n",
    "- Microfilm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SZv5MiVzynG1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\FACULTAD\\ESPECIALIZACIÓN\\4. CUARTO BIMESTRE\\NLP\\env\\lib\\site-packages\\gradio\\deprecation.py:40: UserWarning: `layout` parameter is deprecated, and it has no effect\n",
      "  warnings.warn(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"900\" height=\"500\" allow=\"autoplay; camera; microphone;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: Vannebar Bush\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\FACULTAD\\ESPECIALIZACIÓN\\4. CUARTO BIMESTRE\\NLP\\env\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: in 1962, engelbart sent bush a draft article for comment, bush never replied.\n",
      "Q: Memory\n",
      "A: the name memex is a portmanteau of memory and expansion.\n",
      "Q: Memory\n",
      "A: the name memex is a portmanteau of memory and expansion.\n",
      "Q: hypertext\n",
      "A: in 1968, nelson collaborated with andries van dam to implement the hypertext editing system (hes).\n",
      "Q: memex\n",
      "A: the top of the memex would have a transparent platen.\n",
      "Q: device\n",
      "\n",
      "A: the article claims that magnetic tape would be central to the creation of a modern memex device.\n",
      "Q: documents\n",
      "\n",
      "A: memex is a hypothetical electromechanical device for interacting with microform documents and described in vannevar bush's 1945 article \"as we may think\".\n",
      "Q: technological\n",
      "\n",
      "A: published 22 years after his initial conception of the memex, bush details the various technological advancements that have made his vision a possibility.\n",
      "Q: colombia\n",
      "\n",
      "A: I am sorry, I could not understand you\n",
      "Q: digital\n",
      "\n",
      "A: bush also relates that, unlike digital technology, memex would be of no significant aid to business or profitable ventures, and as a consequence, its development would occur only long after the mechanization of libraries and the introduction of what he describes as the specialized \"group machine\", which would be useful for the sharing of ideas in fields such as medicine.\n",
      "Q: hypertext\n",
      "\n",
      "A: in 1968, nelson collaborated with andries van dam to implement the hypertext editing system (hes).\n",
      "Q: Memex\n",
      "A: the top of the memex would have a transparent platen.\n",
      "Q: Memex device\n",
      "\n",
      "A: the article claims that magnetic tape would be central to the creation of a modern memex device.\n",
      "Q: Memex microfilm\n",
      "\n",
      "A: most of the microfilm library would have been contained within the desk, but the user could add or remove microfilm reels at will.\n",
      "Q: find information\n",
      "\n",
      "A: at the time, bush saw the current ways of indexing information as limiting and instead proposed a way to store information that was analogous to the mental association of the human brain: storing information with the capability of easy access at a later time using certain cues (in this case, a series of numbers as a code to retrieve data).\n",
      "Q: find information memex\n",
      "\n",
      "A: at the time, bush saw the current ways of indexing information as limiting and instead proposed a way to store information that was analogous to the mental association of the human brain: storing information with the capability of easy access at a later time using certain cues (in this case, a series of numbers as a code to retrieve data).\n",
      "Q: hypotetical\n",
      "\n",
      "\n",
      "A: I am sorry, I could not understand you\n",
      "Q: hypothetical\n",
      "\n",
      "\n",
      "A: memex is a hypothetical electromechanical device for interacting with microform documents and described in vannevar bush's 1945 article \"as we may think\".\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def bot_response(human_text):\n",
    "    print(\"Q:\", human_text)    \n",
    "    resp = generate_response(human_text.lower(), corpus)\n",
    "    print(\"A:\", resp)\n",
    "    return resp\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=bot_response,\n",
    "    inputs=[\"textbox\"],\n",
    "    outputs=\"text\",\n",
    "    layout=\"vertical\")\n",
    "\n",
    "iface.launch(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segunda Prueba\n",
    "\n",
    "La siguiente prueba es con una página que plantea el aprendizaje automático como un nooscopio. \n",
    "\n",
    "Acá el buscador: https://nooscope.ai/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_html = urllib.request.urlopen('https://nooscope.ai/')\n",
    "raw_html = raw_html.read()\n",
    "\n",
    "article_html = bs.BeautifulSoup(raw_html, 'lxml')\n",
    "\n",
    "article_paragraphs = article_html.find_all('p')\n",
    "\n",
    "article_text_2 = ''\n",
    "\n",
    "for para in article_paragraphs:\n",
    "    article_text_2 += para.text\n",
    "\n",
    "article_text_2 = article_text_2.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"download diagram pdf and essay pdf\\n              by vladan joler and matteo pasquinelli\\n              (2020)\\n            the nooscope is a cartography of the limits of artificial intelligence, intended as a provocation to both computer science and the humanities. any map is a partial perspective, a way to provoke debate. similarly, this map is a manifesto — of ai dissidents. its main purpose is to challenge the mystifications of artificial intelligence. first, as a technical definition of intelligence and, second, as a political form that would be autonomous from society and the human.\\n                  1\\n                  in the expression ‘artificial intelligence’ the adjective ‘artificial’ carries the myth of the technology’s autonomy: it hints to caricatural ‘alien minds’ that self-reproduce in silico but, actually, mystifies two processes of proper alienation: the growing geopolitical autonomy of hi-tech companies and the invisibilization of workers’ autonomy worldwide. the modern project to mechanise human reason has clearly mutated, in the 21st century, into a corporate regime of knowledge extractivism and epistemic colonialism.2 this is unsurprising, since machine learning algorithms are the most powerful algorithms for information compression.the purpose of the nooscope map is to secularize ai from the ideological status of ‘intelligent machine’ to one of knowledge instrument. rather than evoking legends of alien cognition, it is more reasonable to consider machine learning as an instrument of knowledge magnification that helps to perceive features, patterns, and correlations through vast spaces of data beyond human reach. in the history of science and technology, this is no news: it has already been pursued by optical instruments throughout the histories of astronomy and medicine.3 in the tradition of science, machine learning is just a nooscope, an instrument to see and navigate the space of knowledge (from the greek skopein ‘to examine, look’ and noos ‘knowledge’).borrowing the idea from gottfried wilhelm leibniz, the nooscope diagram applies the analogy of optical media to the structure of all machine learning apparatuses. discussing the power of his calculus ratiocinator and ‘characteristic numbers’ (the idea to design a numerical universal language to codify and solve all the problems of human reasoning), leibniz made an analogy with instruments of visual magnification such as the microscope and telescope. he wrote: ‘once the characteristic numbers are established for most concepts, mankind will then possess a new instrument which will enhance the capabilities of the mind to a far greater extent than optical instruments strengthen the eyes, and will supersede the microscope and telescope to the same extent that reason is superior to eyesight.’4 although the purpose of this text is not to reiterate the opposition between quantitative and qualitative cultures, leibniz’s credo need not be followed. controversies cannot be conclusively computed. machine learning is not the ultimate form of intelligence.instruments of measurement and perception always come with inbuilt aberrations. in the same way that the lenses of microscopes and telescopes are never perfectly curvilinear and smooth, the logical lenses of machine learning embody faults and biases. to understand machine learning and register its impact on society is to study the degree by which social data are diffracted and distorted by these lenses. this is generally known as the debate on bias in ai, but the political implications of the logical form of machine learning are deeper. machine learning is not bringing a new dark age but one of diffracted rationality, in which, as it will be shown, an episteme of causation is replaced by one of automated correlations. more in general, ai is a new regime of truth, scientific proof, social normativity and rationality, which often does take the shape of a statistical hallucination. this diagram manifesto is another way to say that ai, the king of computation (patriarchal fantasy of mechanised knowledge, ‘master algorithm’ and alpha machine) is naked. here, we are peeping into its black box.on the the invention of metaphors as instrument of knowledge magnification.\\u2028emanuele tesauro, il canocchiale aristotelico [the aristotelian telescope], frontispiece of the 1670 edition, turin.the history of ai is a history of experiments, machine failures, academic controversies, epic rivalries around military funding, popularly known as ‘winters of ai.’5 although corporate ai today describes its power with the language of ‘black magic’ and ‘superhuman cognition’, current techniques are still at the experimental stage.6 ai is now at the same stage as when the steam engine was invented, before the laws of thermodynamics necessary to explain and control its inner workings, had been discovered. similarly, today, there are efficient neural networks for image recognition, but there is no theory of learning to explain why they work so well and how they fail so badly. like any invention, the paradigm of machine learning consolidated slowly, in this case through the last half-century. a master algorithm has not appeared overnight. rather, there has been a gradual construction of a method of computation that still has to find a common language. manuals of machine learning for students, for instance, do not yet share a common terminology. how to sketch, then, a critical grammar of machine learning that may be concise and accessible, without playing into the paranoid game of defining general intelligence?as an instrument of knowledge, machine learning is composed of an object to be observed (training dataset), an instrument of observation (learning algorithm) and a final representation (statistical model). the assemblage of these three elements is proposed here as a spurious and baroque diagram of machine learning, extravagantly termed nooscope.7 staying with the analogy of optical media, the information flow of machine learning is like a light beam that is projected by the training data, compressed by the algorithm and diffracted towards the world by the lens of the statistical model.the nooscope diagram aims to illustrate two sides of machine learning at the same time: how it works and how it fails — enumerating its main components, as well as the broad spectrum of errors, limitations, approximations, biases, faults, fallacies and vulnerabilities that are native to its paradigm.8 this double operation stresses that ai is not a monolithic paradigm of rationality but a spurious architecture made of adapting techniques and tricks. besides, the limits of ai are not simply technical but are imbricated with human bias. in the nooscope diagram the essential components of machine learning are represented at the centre, human biases and interventions on the left, and technical biases and limitations on the right. optical lenses symbolize biases and approximations representing the compression and distortion of the information flow. the total bias of machine learning is represented by the central lens of the statistical model through which the perception of the world is diffracted.the limitations of ai are generally perceived today thanks to the discourse on bias —the amplification of gender, race, ability, and class discrimination by algorithms. in machine learning, it is necessary to distinguish between historical bias, dataset bias, and algorithm bias, all of which occur at different stages of the information flow.9 historical bias (or world bias) is already apparent in society before technological intervention. nonetheless, the naturalisation of such bias, that is the silent integration of inequality into an apparently neutral technology is by itself harmful.10 paraphrasing michelle alexander, ruha benjamin has called it the new jim code: ‘the employment of new technologies that reflect and reproduce existing inequalities but that are promoted and perceived as more objective or progressive than the discriminatory systems of a previous era.’11dataset bias is introduced through the preparation of training data by human operators. the most delicate part of the process is data labelling, in which old and conservative taxonomies can cause a distorted view of the world, misrepresenting social diversities and exacerbating social hierarchies (see below the case of imagenet).algorithmic bias (also known as machine bias, statistical bias or model bias, to which the nooscope diagram gives particular attention) is the further amplification of historical bias and dataset bias by machine learning algorithms. the problem of bias has mostly originated from the fact that machine learning algorithms are among the most efficient for information compression, which engenders issues of information resolution, diffraction and loss.12 since ancient times, algorithms have been procedures of an economic nature, designed to achieve a result in the shortest number of steps consuming the least amount of resources: space, time, energy and labour.13 the arms race of ai companies is, still today, concerned with finding the simplest and fastest algorithms with which to capitalise data. if information compression produces the maximum rate of profit in corporate ai, from the societal point of view, it produces discrimination and the loss of cultural diversity.while the social consequences of ai are popularly understood under the issue of bias, the common understanding of technical limitations is known as the black box problem. the black box effect is an actual issue of deep neural networks (which filter information so much that their chain of reasoning cannot be reversed) but has become a generic pretext for the opinion that ai systems are not just inscrutable and opaque, but even ‘alien’ and out of control.14 the black box effect is part of the nature of any experimental machine at the early stage of development (it has already been noticed that the functioning of the steam engine remained a mystery for some time, even after having been successfully tested). the actual problem is the black box rhetoric, which is closely tied to conspiracy theory sentiments in which ai is an occult power that cannot be studied, known, or politically controlled.mass digitalisation, which expanded with the internet in the 1990s and escalated with datacentres in the 2000s, has made available vast resources of data that, for the first time in history, are free and unregulated. a regime of knowledge extractivism (then known as big data) gradually employed efficient algorithms to extract ‘intelligence’ from these open sources of data, mainly for the purpose of predicting consumer behaviours and selling ads. the knowledge economy morphed into a novel form of capitalism, called cognitive capitalism and then surveillance capitalism, by different authors.15 it was the internet information overflow, vast datacentres, faster microprocessors and algorithms for data compression that laid the groundwork for the rise of ai monopolies in the 21st century.what kind of cultural and technical object is the dataset that constitutes the source of ai? the quality of training data is the most important factor affecting the so-called ‘intelligence’ that machine learning algorithms extract. there is an important perspective to take into account, in order to understand ai as a nooscope. data is the first source of value and intelligence. algorithms are second; they are the machines that compute such value and intelligence into a model. however, training data are never raw, independent and unbiased (they are already themselves ‘algorithmic’).16 the carving, formatting and editing of training datasets is a laborious and delicate undertaking, which is probably more significant for the final results than the technical parameters that control the learning algorithm. the act of selecting one data source rather than another is the profound mark of human intervention into the domain of the ‘artificial’ minds.the training dataset is a cultural construct, not just a technical one. it usually comprises input data that are associated with ideal output data, such as pictures with their descriptions, also called labels or metadata.17 the canonical example would be a museum collection and its archive, in which artworks are organised by metadata such as author, year, medium, etc. the semiotic process of assigning a name or a category to a picture is never impartial; this action leaves another deep human imprint on the final result of machine cognition. a training dataset for machine learning is usually composed through the following steps: 1) production: labour or phenomena that produce information; 2) capture: encoding of information into a data format by an instrument: 3) formatting: organisation of data into a dataset: 4) labelling: in supervised learning, the classification of data into categories (metadata).machine intelligence is trained on vast datasets that are accumulated in ways neither technically neutral nor socially impartial. raw data does not exist, as it is dependent on human labour, personal data, and social behaviours that accrue over long periods, through extended networks and controversial taxonomies.18 the main training datasets for machine learning (nmist, imagenet, labelled faces in the wild, etc.) originated in corporations, universities, and military agencies of the global north. but taking a more careful look, one discovers a profound division of labour that innervates into the global south via crowdsourcing platforms that are used to edit and validate data.19 the parable of the imagenet dataset exemplifies the troubles of many ai datasets. imagenet is a training dataset for deep learning that has become the de facto benchmark for image recognition algorithms: indeed, the deep learning revolution started in 2012 when alex krizhevsky, ilya sutskever and geoffrey hinton won the annual imagenet challenge with the convolutional neural network alexnet.20 imagenet was initiated by computer scientist fei-fei li back in 2006.21 fei-fei li had three intuitions to build a reliable dataset for image recognition. first, to download millions of free images from web services such as flickr and google. second, to adopt the computational taxonomy wordnet for image labels.22 third, to outsource the work of labelling millions of images via the crowdsourcing platform amazon mechanical turk. at the end of the day (and of the assembly line), anonymous workers from all over the planet were paid few cents per task to label hundreds of pictures per minute according to the wordnet taxonomy: their labour resulted in the engineering of a controversial cultural construct. ai scholars kate crawford and artist trevor paglen have investigated and disclosed the sedimentation of racist and sexist categories in imagenet taxonomy: see the legitimation of the category ‘failure, loser, nonstarter, unsuccessful person’ for a hundred arbitrary pictures of people.23the voracious data extractivism of ai has caused an unforeseeable backlash on digital culture: in the early 2000s, lawrence lessig could not predict that the large repository of online images credited by creative commons licenses would a decade later become an unregulated resource for face recognition surveillance technologies. in similar ways, personal data is continually incorporated without transparency into privatised datasets for machine learning. in 2019 artist and ai researcher adam harvey for the first time disclosed the nonconsensual use of personal photos in training datasets for face recognition. harvey’s disclosure caused stanford university, duke university and microsoft to withdraw their datasets amidst a major privacy infringement scandal.24 online training datasets trigger issues of data sovereignty and civil rights that traditional institutions are slow to counteract (see the european general data protection regulation).25 if 2012 was the year in which the deep learning revolution began, 2019 was the year in which its sources were discovered to be vulnerable and corrupted.combinatorial patterns and kufic scripts, topkapi scroll, ca. 1500, iran.\\n                  the need to demystify ai (at least from the technical point of view) is understood in the corporate world too. head of facebook ai and godfather of convolutional neural networks yann lecun reiterates that current ai systems are not sophisticated versions of cognition, but rather, of perception. similarly, the nooscope diagram exposes the skeleton of the ai black box and shows that ai is not a thinking automaton but an algorithm that performs pattern recognition. the notion of pattern recognition contains issues that must be elaborated upon. what is a pattern, by the way? is a pattern uniquely a visual entity? what does it mean to read social behaviours as patterns? is pattern recognition an exhaustive definition of intelligence? most likely not. to clarify these issues, it would be good to undertake a brief archaeology of ai.the archetype machine for pattern recognition is frank rosenblatt’s perceptron. invented in 1957 at cornell aeronautical laboratory in buffalo, new york, its name is a shorthand for ‘perceiving and recognizing automaton.’26 given a visual matrix of 20x20 photoreceptors, the perceptron can learn how to recognise simple letters. a visual pattern is recorded as an impression on a network of artificial neurons that are firing up in concert with the repetition of similar images and activating one single output neuron. the output neuron fires 1=true, if a given image is recognised, or 0=false, if a given image is not recognised.the automation of perception, as a visual montage of pixels along a computational assembly line, was originally implicit mcculloch and pitt’s concept of artificial neural networks.27 once the algorithm for visual pattern recognition survived the ‘winter of ai’ and proved efficient in the late 2000s, it was applied also to non-visual datasets, properly inaugurating the age of deep learning (the application of pattern recognition techniques to all kinds of data, not just visual). today, in the case of self-driving cars, the patterns that need to be recognised are objects in road scenarios. in the case of automatic translation, the patterns that need to be recognised are the most common sequences of words across bilingual texts. regardless of their complexity, from the numerical perspective of machine learning, notions such as image, movement, form, style, and ethical decision can all be described as statistical distributions of pattern. in this sense, pattern recognition has truly become a new cultural technique that is used in various fields. for explanatory purposes, the nooscope is described as a machine that operates on three modalities: training, classification, and prediction. in more intuitive terms, these modalities can be called: pattern extraction, pattern recognition, and pattern generation.rosenblatt’s perceptron was the first algorithm that paved the way to machine learning in the contemporary sense. at a time when ‘computer science’ had not yet been adopted as definition, the field was called ‘computational geometry’ and specifically ‘connectionism’ by rosenblatt himself. the business of these neural networks, however, was to calculate a statistical inference. what a neural network computes, is not an exact pattern but the statistical distribution of a pattern. just scraping the surface of the anthropomorphic marketing of ai, one finds another technical and cultural object that needs examination: the statistical model. what is the statistical model in machine learning? how is it calculated? what is the relationship between a statistical model and human cognition? these are crucial issues to clarify. in terms of the work of demystification that needs to be done (also to evaporate some naïve questions), it would be good to reformulate the trite question ‘can a machine think?’ into the theoretically sounder questions ‘can a statistical model think?’, ‘can a statistical model develop consciousness?’, et cetera.the algorithms of ai are often evoked as alchemic formulas, capable of distilling ‘alien’ forms of intelligence. but what do the algorithms of machine learning really do? few people, including the followers of agi (artificial general intelligence), bother to ask this question. algorithm is the name of a process, whereby a machine performs a calculation. the product of such machine processes is a statistical model (more accurately termed an ‘algorithmic statistical model’). in the developer community, the term ‘algorithm’ is increasingly replaced with ‘model.’ this terminological confusion arises from the fact that the statistical model does not exist separately from the algorithm: somehow, the statistical model exists inside the algorithm under the form of distributed memory across its parameters. for the same reason, it is essentially impossible to visualise an algorithmic statistical model, as is done with simple mathematical functions. still, the challenge is worthwhile.in machine learning, there are many algorithm architectures: simple perceptron, deep neural network, support vector machine, bayesian network, markov chain, autoencoder, boltzmann machine, etc. each of these architectures has a different history (often rooted in military agencies and corporations of the global north). artificial neural networks started as simple computing structures that evolved into complex ones which are now controlled by a few hyperparameters that express millions of parameters.28 for instance, convolutional neural networks are described by a limited set of hyperparameters (number of layers, number of neurons per layer, type of connection, behaviour of neurons, etc.) that project a complex topology of thousands of artificial neurons with millions of parameters in total. the algorithm starts as a blank slate and, during the process called training, or ‘learning from data', adjusts its parameters until it reaches a good representation of the input data. in image recognition, as already seen, the computation of millions of parameters has to resolve into a simple binary output: 1=true, a given image is recognised; or 0=false, a given image is not recognised.29source: www.asimovinstitute.org/neural-network-zoo\\nattempting an accessible explanation of the relationship between algorithm and model, let’s have a look at the complex inception v3 algorithm, a deep convolutional neural network for image recognition designed at google and trained on the imagenet dataset. inception v3 is said to have a 78% accuracy in identifying the label of a picture, but the performance of ‘machine intelligence’ in this case can be measured also by the proportion between the size of training data and the trained algorithm (or model). imagenet contains 14 million images with associated labels that occupy approximately 150 gigabytes of memory. on the other hand, inception v3, which is meant to represent the information contained in imagenet, is only 92 megabytes. the ratio of compression between training data and model partially describes also the rate of information diffraction. a table from the keras documentation compares these values (numbers of parameters, layer depth, file dimension and accuracy) for the main models of image recognition.30 this is a brutalist but effective way to show the relation between model and data, to show how the ‘intelligence’ of algorithms is measured and assessed in the developer community.source: keras.io/applicationsstatistical models have always influenced culture and politics. they did not just emerge with machine learning: machine learning is just a new way to automate the technique of statistical modelling. when greta thunberg warns ‘listen to science.’ what she really means, being a good student of mathematics, is ‘listen to the statistical models of climate science.’ no statistical models, no climate science: no climate science, no climate activism. climate science is indeed a good example to start with, in order to understand statistical models. global warming has been calculated by first collecting a vast dataset of temperatures from earth’s surface each day of the year, and second, by applying a mathematical model that plots the curve of temperature variations in the past and projects the same pattern into the future.31 climate models are historical artefacts that are tested and debated within the scientific community, and today, also beyond.32 machine learning models, on the contrary, are opaque and inaccessible to community debate. given the degree of myth-making and social bias around its mathematical constructs, ai has indeed inaugurated the age of statistical science fiction. nooscope is the projector of this large statistical cinema.‘all models are wrong, but some are useful’ — the canonical dictum of the british statistician george box has long encapsulated the logical limitations of statistics and machine learning.33 this maxim, however, is often used to legitimise the bias of corporate and state ai. computer scientists argue that human cognition reflects the capacity to abstract and approximate patterns. so what’s the problem with machines being approximate, and doing the same? within this argument, it is rhetorically repeated that ‘the map is not the territory’. this sounds reasonable. but what should be contested is that ai is a heavily compressed and distorted map of the territory and that this map, like many forms of automation, is not open to community negotiation. ai is a map of the territory without community access and community consent.34how does machine learning plot a statistical map of the world? let’s face the specific case of image recognition (the basic form of the labour of perception, which has been codified and automated as pattern recognition).35 given an image to be classified, the algorithm detects the edges of an object as the statistical distribution of dark pixels surrounded by light ones (a typical visual pattern). the algorithm does not know what an image is, does not perceive an image as human cognition does, it only computes pixels, numerical values of brightness and proximity. the algorithm is programmed to record only the dark edge of a profile (that is to fit that desired pattern) and not all the pixels across the image (that would result in overfitting and repeating the whole visual field). a statistical model is said to be trained successfully when it can elegantly fit only the important patterns of the training data and apply those patterns also to new data ‘in the wild’. if a model learns the training data too well, it recognises only exact matches of the original patterns and will overlook those with close similarities, ‘in the wild’. in this case, the model is overfitting, because it has meticulously learnt everything (including noise) and is not able to distinguish a pattern from its background. on the other hand, the model is underfitting when it is not able to detect meaningful patterns from the training data. the notions of data overfitting, fitting and underfitting can be visualised on a cartesian plane.the challenge of guarding the accuracy of machine learning lays in calibrating the equilibrium between data underfitting and overfitting, which is difficult to do because of different machine biases. machine learning is a term that, as much as ‘ai', anthropomorphizes a piece of technology: machine learning learns nothing in the proper sense of the word, as a human does; machine learning simply maps a statistical distribution of numerical values and draws a mathematical function that hopefully approximates human comprehension. that being said, machine learning can, for this reason, cast new light on the ways in which humans comprehend.the statistical model of machine learning algorithms is also an approximation in the sense that it guesses the missing parts of the data graph: either through interpolation, which is the prediction of an output y within the known interval of the input x in the training dataset, or through extrapolation, which is the prediction of output y beyond the limits of x, often with high risks of inaccuracy. this is what ‘intelligence’ means today within machine intelligence: to extrapolate a non-linear function beyond known data boundaries. as dan mcquillian aptly puts it: ‘there is no intelligence in artificial intelligence, nor does it learn, even though its technical name is machine learning, it is simply mathematical minimization.’36it is important to recall that the ‘intelligence’ of machine learning is not driven by exact formulas of mathematical analysis, but by algorithms of brute force approximation. the shape of the correlation function between input x and output y is calculated algorithmically, step by step, through tiresome mechanical processes of gradual adjustment (like gradient descent, for instance) that are equivalent to the differential calculus of leibniz and newton. neural networks are said to be among the most efficient algorithms because these differential methods can approximate the shape of any function given enough layers of neurons and abundant computing resources.37 brute-force gradual approximation of a function is the core feature of today’s ai, and only from this perspective can one understand its potentialities and limitations — particularly its escalating carbon footprint (the training of deep neural networks requires exorbitant amounts of energy because of gradient descent and similar training algorithms that operate on the basis of continuous infinitesimal adjustments).38the notions of data fitting, overfitting, underfitting, interpolation and extrapolation can be easily visualised in two dimensions, but statistical models usually operate along multidimensional spaces of data. before being analysed, data are encoded into a multi-dimensional vector space that is far from intuitive. what is a vector space and why is it multi-dimensional? cardon, cointet and mazière describe the vectorialisation of data in this way:a neural network requires the inputs of the calculator to take on the form of a vector. therefore, the world must be coded in advance in the form of a purely digital vectorial representation. while certain objects such as images are naturally broken down into vectors, other objects need to be ‘embedded’ within a vectorial space before it is possible to calculate or classify them with neural networks. this is the case of text, which is the prototypical example. to input a word into a neural network, the word2vec technique ‘embeds’ it into a vectorial space that measures its distance from the other words in the corpus. words thus inherit a position within a space with several hundreds of dimensions. the advantage of such a representation resides in the numerous operations offered by such a transformation. two terms whose inferred positions are near one another in this space are equally similar semantically; these representations are said to be distributed: the vector of the concept ‘apartment’ [-0.2, 0.3, -4.2, 5.1...] will be similar to that of ‘house’ [-0.2, 0.3, -4.0, 5.1...]. […] while natural language processing was pioneering for ‘embedding’ words in a vectorial space, today we are witnessing a generalization of the embedding process which is progressively extending to all applications fields: networks are becoming simple points in a vectorial space with graph2vec, texts with paragraph2vec, films with movie2vec, meanings of words with sens2vec, molecular structures with mol2vec, etc. according to yann lecun, the goal of the designers of connectionist machines is to put the world in a vector (world2vec).39multi-dimensional vector space is another reason why the logic of machine learning is difficult to grasp. vector space is another new cultural technique, worth becoming familiar with. the field of digital humanities, in particular, has been covering the technique of vectorialisation through which our collective knowledge is invisibly rendered and processed. william gibson’s original definition of cyberspace prophesized, most likely, the coming of a vector space rather than virtual reality: ‘a graphic representation of data abstracted from the banks of every computer in the human system. unthinkable complexity. lines of light ranged in the nonspace of the mind, clusters and constellations of data. like city lights, receding.’40\\xa0right: vector space of seven words in three contexts.41it must be stressed, however, that machine learning still resembles more craftsmanship than exact mathematics. ai is still a history of hacks and tricks rather than mystical intuitions. for example, one trick of information compression is dimensionality reduction, which is used to avoid the curse of dimensionality, that is the exponential growth of the variety of features in the vector space. the dimensions of the categories that show low variance in the vector space (i.e. whose values fluctuate only a little) are aggregated to reduce calculation costs. dimensionality reduction can be used to cluster word meanings (such as in the model word2vec) but can also lead to category reduction, which can have an impact on the representation of social diversity. dimensionality reduction can shrink taxonomies and introduce bias, further normalising world diversity and obliterating unique identities.42most of the contemporary applications of machine learning can be described according to the two modalities of classification and prediction, which outline the contours of a new society of control and statistical governance. classification is known as pattern recognition, while prediction can be defined also as pattern generation. a new pattern is recognised or generated by interrogating the inner core of the statistical model.machine learning classification is usually employed to recognise a sign, an object, or a human face, and to assign a corresponding category (label) according to taxonomy or cultural convention. an input file (e.g. a headshot captured by a surveillance camera) is run through the model to determine whether it falls within its statistical distribution or not. if so, it is assigned the corresponding output label. since the times of the perceptron, classification has been the originary application of neural networks: with deep learning this technique is found ubiquitously in face recognition classifiers that are deployed by police forces and smartphone manufacturers alike.machine learning prediction is used to project future trends and behaviours according to past ones, that is to complete a piece of information knowing only a portion of it. in the prediction modality, a small sample of input data (a primer) is used to predict the missing part of the information following once again the statistical distribution of the model (this could be the part of a numerical graph oriented toward the future or the missing part of an image or audio file). incidentally, other modalities of machine learning exist: the statistical distribution of a model can be dynamically visualised through a technique called latent space exploration and, in some recent design applications, also pattern exploration.43machine learning classification and prediction are becoming ubiquitous techniques that constitute new forms of surveillance and governance. some apparatuses, such as self-driving vehicles and industrial robots, can be an integration of both modalities. a self-driving vehicle is trained to recognise different objects on the road (people, cars, obstacles, signs) and predict future actions based on decisions that a human driver has taken in similar circumstances. even if recognising an obstacle on a road seems to be a neutral gesture (it’s not), identifying a human being according to categories of gender, race and class (and in the recent covid-19 pandemic as sick or immune), as state institutions are increasingly doing, is the gesture of a new disciplinary regime. the hubris of automated classification has caused the revival of reactionary lombrosian techniques that were thought to have been consigned to history, techniques such as automatic gender recognition (agr), ‘a subfield of facial recognition that aims to algorithmically identify the gender of individuals from photographs or videos.’44recently, the generative modality of machine learning has had a cultural impact: its use in the production of visual artefacts has been received by mass media as the idea that artificial intelligence is ‘creative’ and can autonomously make art. an artwork that is said to be created by ai always hides a human operator, who has applied the generative modality of a neural network trained on a specific dataset. in this modality, the neural network is run backwards (moving from the smaller output layer toward the larger input layer) to generate new patterns after being trained at classifying them, a process that usually moves from the larger input layer to the smaller output layer. the generative modality, however, has some useful applications: it can be used as a sort of reality check to reveal what the model has learnt, i.e. to show how the model ‘sees the world.’ it can be applied to the model of a self-driving car, for instance, to check how the road scenario is projected.a famous way to illustrate how a statistical model ‘sees the world’ is google deepdream. deepdream is a convolutional neural network based on inception (which is trained on the imagenet dataset mentioned above) that was programmed by alexander mordvintsev to project hallucinatory patterns. mordvintsev had the idea to ‘turn the network upside down’, that is to turn a classifier into a generator, using some random noise or generic landscape images as input.45 he discovered that ‘neural networks that were trained to discriminate between different kinds of images have quite a bit of the information needed to generate images too.’ in deepdream first experiments, bird feathers and dog eyes started to emerge everywhere as dog breeds and bird species are vastly overrepresented in imagenet. it was also discovered that the category ‘dumbbell’ was learnt with a surreal human arm always attached to it. proof that many other categories of imagenet are misrepresented.the two main modalities of classification and generation can be assembled in further architectures such as in the generative adversarial networks. in the gan architecture, a neural network with the role of discriminator (a traditional classifier) has to recognise an image produced by a neural network with the role of generator, in a reinforcement loop that trains the two statistical models simultaneously. for some converging properties of their respective statistical models, gans have proved very good at generating highly realistic pictures. this ability has prompted their abuse in the fabrication of ‘deep fakes’.46 concerning regimes of truth, a similar controversial application is the use of gans to generate synthetic data in cancer research, in which neural networks trained on unbalanced datasets of cancer tissues have started to hallucinate cancer where there was none.47 in this case ‘instead of discovering things, we are inventing things', fabian offert notices, ‘the space of discovery is identical to the space of knowledge that the gan has already had. […] while we think that we are seeing through gan — looking at something with the help of a gan — we are actually seeing into a gan. gan vision is not augmented reality, it is virtual reality. gans do blur discovery and invention.’48 the gan simulation of brain cancer is a tragic example of ai-driven scientific hallucination.joseph paul cohen, margaux luck and sina honari. ‘distribution matching losses can\\u2028hallucinate features in medical image translation’, 2018. courtesy of the authors.the normative power of ai in the 21st century has to be scrutinised in these epistemic terms: what does it mean to frame collective knowledge as patterns, and what does it mean to draw vector spaces and statistical distributions of social behaviours? according to foucault, in early modern france, statistical power was already used to measure social norms, discriminating between normal and abnormal behaviour.49 ai easily extends the ‘power of normalisation’ of modern institutions, among others bureaucracy, medicine and statistics (originally, the numerical knowledge possessed by the state about its population) that passes now into the hands of ai corporations. the institutional norm has become a computational one: the classification of the subject, of bodies and behaviours, seems no longer to be an affair for public registers, but instead for algorithms and datacentres.50 ‘data-centric rationality’, paula duarte has concluded, ‘should be understood as an expression of the coloniality of power.’51a gap, a friction, a conflict, however, always persists between ai statistical models and the human subject that is supposed to be measured and controlled. this logical gap between ai statistical models and society is usually debated as bias. it has been extensively demonstrated how face recognition misrepresents social minorities and how black neighbourhoods, for instance, are bypassed by ai-driven logistics and delivery service.52 if gender, race and class discriminations are amplified by ai algorithms, this is also part of a larger problem of discrimination and normalisation at the logical core of machine learning. the logical and political limitation of ai is the technology’s difficulty in the recognition and prediction of a new event. how is machine learning dealing with a truly unique anomaly, an uncommon social behaviour, an innovative act of disruption? the two modalities of machine learning display a limitation that is not simply bias.a logical limit of machine learning classification, or pattern recognition, is the inability to recognise a unique anomaly that appears for the first time, such as a new metaphor in poetry, a new joke in everyday conversation, or an unusual obstacle (a pedestrian? a plastic bag?) on the road scenario. the undetection of the new (something that has never ‘been seen’ by a model and therefore never classified before in a known category) is a particularly hazardous problem for self-driving cars and one that has already caused fatalities. machine learning prediction, or pattern generation, show similar faults in the guessing of future trends and behaviours. as a technique of information compression, machine learning automates the dictatorship of the past, of past taxonomies and behavioural patterns, over the present. this problem can be termed the regeneration of the old — the application of a homogenous space-time view that restrains the possibility of a new historical event.interestingly, in machine learning, the logical definition of a security issue also describes the logical limit of its creative potential. the problems characteristic of the prediction of the new are logically related to those that characterise the generation of the new, because the way a machine learning algorithm predicts a trend on a time chart is identical to the way it generates a new artwork from learnt patterns. the hackneyed question ‘can ai be creative?’ should be reformulated in technical terms: is machine learning able to create works that are not imitations of the past? is machine learning able to extrapolate beyond the stylistic boundaries of its training data? the ‘creativity’ of machine learning is limited to the detection of styles from the training data and then random improvisation within these styles. in other words, machine learning can explore and improvise only within the logical boundaries that are set by the training data. for all these issues, and its degree of information compression, it would be more accurate to term machine learning art as statistical art. lewis fry richardson, weather prediction by numerical process, cambridge university press, 1922.another unspoken bug of machine learning is that the statistical correlation between two phenomena is often adopted to explain causation from one to the other. in statistics, it is commonly understood that correlation does not imply causation, meaning that a statistical coincidence alone is not sufficient to demonstrate causation. a tragic example can be found in the work of statistician frederick hoffman, who in 1896 published a 330-page report for insurance companies to demonstrate a racial correlation between being a black american and having short life expectancy.53 superficially mining data, machine learning can construct any arbitrary correlation that is then perceived as real. in 2008 this logical fallacy was proudly embraced by wired director chris anderson who declared the ‘end of theory’ because ‘the data deluge makes the scientific method obsolete.’54 according to anderson, himself no expert on scientific method and logical inference, statistical correlation is enough for google to run its ads business, therefore it must also be good enough to automatically discover scientific paradigms. even judea pearl, a pioneer of bayesian networks, believes that machine learning is obsessed with ‘curve fitting’, recording correlations without providing explanations.55 such a logical fallacy has already become a political one, if one considers that police forces worldwide have adopted predictive policing algorithms.56 according to dan mcquillan, when machine learning is applied to society in this way, it turns into a biopolitical apparatus of preemption, that produces subjectivities which can subsequently be criminalized.57 ultimately, machine learning obsessed with ‘curve fitting’ imposes a statistical culture and replaces the traditional episteme of causation (and political accountability) with one of correlations blindly driven by the automation of decision making.so far the statistical diffractions and hallucinations of machine learning have been followed step by step through the multiple lenses of the nooscope. at this point, the orientation of the instrument has to be reversed: scientific theories as much as computational devices are inclined to consolidate an abstract perspective — the scientific ‘view from nowhere’, that is often just the point of view of power. the obsessive study of ai can suck the scholar into an abyss of computation and the illusion that the technical form illuminates the social one. as paola ricaurte remarks: ‘data extractivism assumes that everything is a data source.’58 how to emancipate ourselves from a data-centric view of the world? it is time to realise that it is not the statistical model that constructs the subject, but rather the subject that structures the statistical model. internalist and externalist studies of ai have to blur: subjectivities make the mathematics of control from within, not from without. to second what guattari once said of machines in general, machine intelligence too is constituted of ‘hyper-developed and hyper-concentrated forms of certain aspects of human subjectivity.’59rather than studying only how technology works, critical inquiry studies also how it breaks, how subjects rebel against its normative control and workers sabotage its gears. in this sense, a way to sound the limits of ai is to look at hacking practices. hacking is an important method of knowledge production, a crucial epistemic probe into the obscurity of ai.60 deep learning systems for face recognition have triggered, for instance, forms of counter-surveillance activism. through techniques of face obfuscation, humans have decided to become unintelligible to artificial intelligence: that is to become, themselves, black boxes. the traditional techniques of obfuscation against surveillance immediately acquire a mathematical dimension in the age of machine learning. for example, ai artist and researcher adam harvey has invented a camouflage textile called hyperface that fools computer vision algorithms to see multiple human faces where there is none.61 harvey's work provokes the question: what constitutes a face for a human eye, on the one hand, and a computer vision algorithm, on the other? the neural glitches of hyperface exploit such a cognitive gap and reveal what a human face looks like to a machine. this gap between human and machine perception helps to introduce the growing field of adversarial attacks.adam harvey, hyperface pattern, 2016.adversarial attacks exploit blind spots and weak regions in the statistical model of a neural network, usually to fool a classifier and make it perceive something that is not there. in object recognition, an adversarial example can be a doctored image of a turtle, which looks innocuous to a human eye but gets misclassified by a neural network as a rifle.62 adversarial examples can be realised as 3d objects and even stickers for road signs that can misguide self-driving cars (which may read a speed limit of 120 km/h where it is actually 50 km/h).63 adversarial examples are designed knowing what a machine has never seen before. this effect is achieved also by reverse-engineering the statistical model or by polluting the training dataset. in this latter sense, the technique of data poisoning targets the training dataset and introduces doctored data. in so doing it alters the accuracy of the statistical model and creates a backdoor that can be eventually exploited by an adversarial attack.64adversarial attack seems to point to a mathematical vulnerability that is common to all machine learning models: ‘an intriguing aspect of adversarial examples is that an example generated for one model is often misclassified by other models, even when they have different architectures or were trained on disjoint training sets.’65 adversarial attacks remind us of the discrepancy between human and machine perception and that the logical limit of machine learning is also a political one. the logical and ontological boundary of machine learning is the unruly subject or anomalous event that escapes classification and control. the subject of algorithmic control fires back. adversarial attacks are a way to sabotage the assembly line of machine learning by inventing a virtual obstacle that can set the control apparatus out of joint. an adversarial example is the sabot in the age of ai.the natures of the ‘input’ and ‘output’ of machine learning have to be clarified. ai troubles are not only about information bias but also labour. ai is not just a control apparatus, but also a productive one. as just mentioned, an invisible workforce is involved in each step of its assembly line (dataset composition, algorithm supervision, model evaluation, etc.). pipelines of endless tasks innervate from the global north into the global south; crowdsourced platforms of workers from venezuela, brazil and italy, for instance, are crucial in order to teach german self-driving cars ‘how to see.’66 against the idea of alien intelligence at work, it must be stressed that in the whole computing process of ai the human worker has never left the loop, or put more accurately, has never left the assembly line. mary gray and siddharth suri coined the term ‘ghost work’ for the invisible labour that makes ai appear artificially autonomous.beyond some basic decisions, today’s artificial intelligence can’t function without humans in the loop. whether it’s delivering a relevant newsfeed or carrying out a complicated texted-in pizza order, when the artificial intelligence (ai) trips up or can’t finish the job, thousands of businesses call on people to quietly complete the project. this new digital assembly line aggregates the collective input of distributed workers, ships pieces of projects rather than products, and operates across a host of economic sectors at all times of the day and night.automation is a myth; because machines, including ai, constantly call for human help, some authors have suggested replacing ‘automation’ with the more accurate term heteromation.67 heteromation means that the familiar narrative of ai as perpetuum mobile is possible only thanks to a reserve army of workers.yet there is a more profound way in which labour constitutes ai. the information source of machine learning (whatever its name: input data, training data or just data) is always a representation of human skills, activities and behaviours, social production at large. all training datasets are, implicitly, a diagram of the division of human labour that ai has to analyse and automate. datasets for image recognition, for instance, record the visual labour that drivers, guards, and supervisors usually perform during their tasks. even scientific datasets rely on scientific labour, experiment planning, laboratory organisation, and analytical observation. the information flow of ai has to be understood as an apparatus designed to extract ‘analytical intelligence’ from the most diverse forms of labour and to transfer such intelligence into a machine (obviously including, within the definition of labour, extended forms of social, cultural and scientific production).68 in short, the origin of machine intelligence is the division of labour and its main purpose is the automation of labour.historians of computation have already stressed the early steps of machine intelligence in the 19th century project of mechanizing the division of mental labour, specifically the task of hand calculation.69 the enterprise of computation has since then been a combination of surveillance and disciplining of labour, of optimal calculation of surplus-value, and planning of collective behaviours.70 computation was established by and still enforces a regime of visibility and intelligibility, not just of logical reasoning. the genealogy of ai as an apparatus of power is confirmed today by its widespread employment in technologies of identification and prediction, yet the core anomaly which always remains to be computed is the disorganisation of labour.as a technology of automation, ai will have a tremendous impact on the job market. if deep learning has a 1% error rate in image recognition, for example, it means that roughly 99% of routine work based on visual tasks (e.g. airport security) can be potentially replaced (legal restrictions and trade union opposition permitting). the impact of ai on labour is well described (from the perspective of workers, finally) within a paper from the european trade union institute, which highlights ‘seven essential dimensions that future regulation should address in order to protect workers: 1) safeguarding worker privacy and data protection; 2) addressing surveillance, tracking and monitoring; 3) making the purpose of ai algorithms transparent; 4) ensuring the exercise of the ‘right to explanation’ regarding decisions made by algorithms or machine learning models; 5) preserving the security and safety of workers in human-machine interactions; 6) boosting workers’ autonomy in human–machine interactions; 7) enabling workers to become ai literate.’71\\xa0ultimately, the nooscope manifests for a novel machinery question in the age of ai. the machinery question was a debate that sparked in england during the industrial revolution, when the response to the employment of machines and workers’ subsequent technological unemployment was a social campaign for more education about machines, that took the form of the mechanics’ institute movement.72 today an intelligent machinery question is needed to develop more collective intelligence about ‘machine intelligence,’ more public education instead of ‘learning machines’ and their regime of knowledge extractivism (which reinforces old colonial routes, just by looking at the network map of crowdsourcing platforms today). also in the global north, this colonial relationship between corporate ai and the production of knowledge as a common good has to be brought to the fore. the nooscope’s purpose is to expose the hidden room of the corporate mechanical turk and to illuminate the invisible labour of knowledge that makes machine intelligence appear ideologically alive. on the autonomy of technology see: langdon winner, autonomous technology: technics-out-of-control as a theme in political thought. cambridge, ma: mit press, 2001. for the extension of colonial power into the operations of logistics, algorithms and finance see: sandro mezzadra and brett neilson, the politics of operations: excavating contemporary capitalism. durham: duke university press, 2019. on the epistemic colonialism of ai see: matteo pasquinelli, ‘three thousand years of algorithmic rituals.’ e-flux 101, 2019. digital humanities term a similar technique distant reading, which has gradually involved data analytics and machine learning in literary and art history. see: franco moretti, distant reading. london: verso, 2013. gottfried w. leibniz, ‘preface to the general science’, 1677. in: phillip wiener (ed.) leibniz selections. new york: scribner, 1951, 23. for a concise history of ai see: dominique cardon, jean-philippe cointet and antoine mazières, ‘neurons spike back: the invention of inductive machines and the artificial intelligence controversy.’ réseaux 211, 2018. alexander campolo and kate crawford, ‘enchanted determinism: power without control in artificial intelligence.’ engaging science, technology, and society 6, 2020. the use of the visual analogy is also intended to record the fading distinction between image and logic, representation and inference, in the technical composition of ai. the statistical models of machine learning are operative representations (in the sense of harun farocki’s operative images). for a systematic study of the logical limitations of machine learning see: momin mailk, ‘a hierarchy of limitations in machine learning.’ arxiv preprint, 2020. https://arxiv.org/abs/2002.05193 for a more detailed list of ai biases see: john guttag and harini suresh, ‘a framework for understanding unintended consequences of machine learning.’ arxiv preprint, 2019. https://arxiv.org/abs/1901.10002 see also: aram galstyan, kristin lerman, ninareh mehrabi, fred morstatter and nripsuta saxena, ‘a survey on bias and fairness in machine learning.’\\xa0arxiv preprint, 2019. https://arxiv.org/abs/1908.09635\\xa0 virginia eubanks, automating inequality. new york: st. martin’s press, 2018. see also: kate crawford, ‘the trouble with bias.’ keynote lecture, conference on neural information processing systems, 2017. ruha benjamin, race after technology: abolitionist tools for the new jim code. cambridge, uk: polity, 2019, 5. computer scientists argue that ai belongs to a subfield of signal processing, that is data compression. matteo pasquinelli, the eye of the master. london: verso, forthcoming. projects such as explainable artificial intelligence, interpretable deep learning and heatmapping among others have demonstrated that breaking into the ‘black box’ of machine learning is possible. nevertheless, the full interpretability and explicability of machine learning statistical models remains a myth. see: zacharay lipton, ‘the mythos of model interpretability.’ arxiv preprint, 2016. https://arxiv.org/abs/1606.03490 a. corsani, b. paulré, c. vercellone, j.m. monnier, m. lazzarato, p. dieuaide and y. moulier-boutang, ‘le capitalisme cognitif comme sortie de la crise du capitalisme industriel. un programme de recherché’, paris: laboratoire isys\\xa0matisse, maison des sciences economiques, 2004. see also: zuboff, shoshana, the age of surveillance capitalism: the fight for a human future at the new frontier of power. london: profile books, 2019. lisa gitelman (ed.), raw data is an oxymoron, cambridge, ma: mit press, 2013. in supervised learning. also self-supervised learning maintains forms of human intervention. on taxonomy as a form of knowledge and power see: michel foucault, the order of things. london: routledge, 2005. such as amazon mechanical turk, cynically termed ‘artificial artificial intelligence’ by jeff bezos. see: jason pontin, ‘artificial intelligence, with help from the humans.’ the new york times, 25 march 2007. although the convolutional architecture dates back to yann lecunn’s work in the late 1980s, deep learning starts with this paper: geoffrey hinton, alex krizhevsky and ilya sutskever, ‘imagenet classification with deep convolutional neural networks.’ communications of the acm 60(6), 2017. for an accessible (yet not very critical) account of the imagenet development see: melanie mitchell, artificial intelligence: a guide for thinking humans. london: penguin, 2019. wordnet is ‘a lexical database of semantic relations between words’ which was initiated by george armitage at princeton university in 1985. it provides a strict tree-like structure of definitions. kate crawford and trevor paglen, ‘excavating ai: the politics of training sets for machine learning.’ 19 september 2019. https://excavating.ai adam harvey and jules laplace, megapixel project, 2019. https://megapixels.cc/about/ and: madhumita murgia, ‘who's using your face? the ugly truth about facial recognition.’ financial times, 19 april 2019. the gdpr data privacy regulation that was passed by the european parliament in may 2018 is, however, an improvement compared to the regulation that is missing in the united states. frank rosenblatt, ‘the perceptron: a perceiving and recognizing automaton.’ cornell aeronautical laboratory report 85-460-1, 1957. warren mcculloch and walter pitts, ‘how we know universals: the perception of auditory and visual forms.’ the bulletin of mathematical biophysics 9(3): 1947. the parameters of a model that are learnt from data are called ‘parameters’, while parameters that are not learnt from data and are fixed manually are called ‘hyperparameters’ (these determine number and properties of the parameters). this value can be also a percentage value between 1 and 0. https://keras.io/applications (documentation for individual models). paul edwards, a vast machine: computer models, climate data, and the politics of global warming. cambridge, ma: see the the community earth system model (cesm) that has been developed by the national center for atmospheric research in bolder, colorado, since 1996. the community earth system model is a fully coupled numerical simulation of the earth system consisting of atmospheric, ocean, ice, land surface, carbon cycle, and other components. cesm includes a climate model providing state-of-the-art simulations of the earth's past, present, and future.’ http://www.cesm.ucar.edu george box, ‘robustness in the strategy of scientific model building.’ technical report #1954, mathematics research center, university of wisconsin-madison, 1979. post-colonial and post-structuralist schools of anthropology and ethnology have stressed that there is never territory per se, but always an act of territorialisation. pattern recognition is one among many other economies of attention. ‘to look is to labor’, as jonathan beller reminds us. jonathan beller, the cinematic mode of production: attention economy and the society of the spectacle. lebanon, nh: university press of new england, 2006, 2. dan mcquillan, ‘manifesto on algorithmic humanitarianism.’ presented at the symposium reimagining digital humanitarianism, goldsmiths, university of london, february 16, 2018. as proven by the universal approximation theorem. ananya ganesh, andrew mccallum and emma strubell, ‘energy and policy considerations for deep learning in nlp.’ arxiv preprint, 2019. https://arxiv.org/abs/1906.02243 cardon et al, ‘neurons spike back.’ william gibson, neuromancer. new york: ace books, 1984, 69. source: corpling.hypotheses.org/495 jamie morgenstern, samira samadi, mohit singh, uthaipon tantipongpipat and santosh vempala, ‘the price of fair pca: one extra dimension.’ advances in neural information processing systems 31, 2018. see the idea of assisted and generative creation in: roelof pieters and samim winiger, ‘creative ai: on the democratisation and escalation of creativity’, 2016. http://www. medium.com/@creativeai/creativeai-9d4b2346faf3 os keyes, ‘the misgendering machines: trans/hci implications of automatic gender recognition.’ proceedings of the acm on human-computer interaction 2(88), november 2018. https://doi.org/10.1145/3274357 alexander mordvintsev, christophe olah and mike tyka, ‘inceptionism: going deeper into neural networks.’ google research blog, june 17, 2015. https://ai.googleblog.com/2015/06/ inceptionism-going-deeper-into-neural.html deep fakes are synthetic media like videos in which a person's face is replaced with someone else's facial features, often for the purpose to forge fake news. joseph paul cohen, sina honari and margaux luck, ‘distribution matching losses can hallucinate features in medical image translation.’ international conference on medical image computing and computer-assisted intervention. cham: springer, 2018. arxiv:1805.08841 fabian offert, neural network cultures panel, transmediale festival and kim hfg karlsruhe. berlin, 1 february 2020. http://kim.hfg-karlsruhe.de/events/neural-network-cultures michel foucault, abnormal: lectures at the collège de france 1974-1975. new york: picador, 2004, 26. on computational norms see: matteo pasquinelli, ‘arcana mathematica imperii: the evolution of western computational norms.’ in: maria hlavajova et al. (eds), former west. cambridge, ma: mit press, 2017. paola ricaurte, ‘data epistemologies, the coloniality of power, and resistance.’ television & new media, 7 march 2019. david ingold, and spencer soper, ‘amazon doesn’t consider the race of its customers. should it?’, bloomberg, 21 april 2016. https://www.bloomberg.com/graphics/2016-amazon-same-day cathy o’neil, weapons of math destruction. new york: broadway books, 2016, ch 9. chris anderson, ‘the end of theory: the data deluge makes the scientific method obsolete.’ wired, 23 june 2008. for a critique see: fulvio mazzocchi, ‘could big data be the end of theory in science? a few remarks on the epistemology of data-driven science.’ embo reports 16(10), 2015. judea pearl and dana mackenzie, the book of why: the new science of cause and effect. new york: basic books, 2018. experiments by the new york police department since the late 1980s. see: pasquinelli, ‘arcana mathematica imperii.’ dan mcquillan, ‘people’s councils for ethical machine learning.’ social media and society 4(2), 2018. ricaurte, ‘data epistemologies.’ felix guattari, schizoanalytic cartographies. london: continuum, 2013, 2. the relationship between ai and hacking is not as antagonistic as it may appear: it often resolves in a loop of mutual learning, evaluation and reinforcement. adam harvey, hyperface project, 2016. https://ahprojects.com/hyperface anish athalye et al., ‘synthesizing robust adversarial examples.’ arxiv preprint, 2017. https://arxiv.org/abs/1707.07397 nir morgulis et al., ‘fooling a real car with adversarial traffic signs.’ arxiv preprint, 2019. https://arxiv.org/abs/1907.00374 data poisoning can also be employed to protect privacy by entering anonymized or random information into the dataset. ian goodfellow et al., ‘explaining and harnessing adversarial examples.’ arxiv preprint, 2014. https://arxiv.org/abs/1412.6572 florian schmidt, ‘crowdsourced production of ai training data: how human workers teach self-driving cars to see.’ düsseldorf: hans-böckler-stiftung, 2019. hamid ekbia and bonnie nardi, heteromation, and other stories of computing and capitalism. cambridge, ma: mit press, 2017. for the idea of analytical intelligence see: lorraine daston, ‘calculation and the division of labour 1750–1950.’ bulletin of the german historical institute 62, 2018. simon schaffer, ‘babbage’s intelligence: calculating engines and the factory system’, critical inquiry 21, 1994. lorraine daston, ‘enlightenment calculations’. critical inquiry 21, 1994. matthew l. jones, reckoning with matter: calculating machines, innovation, and thinking about thinking from pascal to babbage. chicago: university of chicago press, 2016. 62, 2018. matteo pasquinelli, ‘on the origins of marx’s general intellect.’ radical philosophy 2.06, 2019. aida ponce, ‘labour in the age of ai: why regulation is needed to protect workers.’ etui research paper - foresight brief 8, 2020. http://dx.doi.org/10.2139/ssrn.3541002 maxine berg, the machinery question and the making of political economy. cambridge, uk: cambridge university press, 1980. in fact, even the economist has recently warned about ‘the return of the machinery question’ in the age of ai. see: tom standage, ‘the return of the machinery question.’ the economist, 23 june 2016.\\ndiagram pdf\\n\\nessay pdf\\nauthors: vladan joler and matteo pasquinellivladan joler is professor at the academy of arts of the university of novi sad and founder of share foundation. he is leading share lab, a research and investigation lab that explores the technical and social aspects of algorithmic transparency, digital labor exploitation, invisible infrastructures, and technological black boxes.matteo pasquinelli is professor in media philosophy at the karlsruhe university of arts and design, where he is coordinating the research group on artificial intelligence and media philosophy kim. for verso books he is preparing a monograph on the history of ai provisionally titled the eye of the master.full citation: matteo pasquinelli and vladan joler, “the nooscope manifested: artificial intelligence as instrument of knowledge extractivism”, visual essay, kim hfg karlsruhe and share lab, 1 may 2020. http://nooscope.aiemail: input [at] nooscope.aiacknowledgements: thanks to jon beller, kate crawford, dubravko ćulibrk, ariana dongus, claire glanois, adam harvey, leonardo impett, arif kornweitz, wietske maas, dan mcquillan, fabian offert, godofredo pereira, johannes paul raether, natascha sadr haghighian, olivia solis, mitch speed and the extended community around kim hfg karlsruhe for their inputs and comments.\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_text_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de caracteres en la nota: 30002\n"
     ]
    }
   ],
   "source": [
    "print(\"Cantidad de caracteres en la nota:\", len(article_text_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sustituir los números que aparecen como citas al final de algunos párrafos\n",
    "text_2 = re.sub(r'\\[0-9]*', ' ', article_text_2)\n",
    "#sustituir más de un caracter de espacio, salto de línea o tabulación\n",
    "text_2 = re.sub(r'\\s+', ' ', article_text_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"download diagram pdf and essay pdf by vladan joler and matteo pasquinelli (2020) the nooscope is a cartography of the limits of artificial intelligence, intended as a provocation to both computer science and the humanities. any map is a partial perspective, a way to provoke debate. similarly, this map is a manifesto — of ai dissidents. its main purpose is to challenge the mystifications of artificial intelligence. first, as a technical definition of intelligence and, second, as a political form that would be autonomous from society and the human. 1 in the expression ‘artificial intelligence’ the adjective ‘artificial’ carries the myth of the technology’s autonomy: it hints to caricatural ‘alien minds’ that self-reproduce in silico but, actually, mystifies two processes of proper alienation: the growing geopolitical autonomy of hi-tech companies and the invisibilization of workers’ autonomy worldwide. the modern project to mechanise human reason has clearly mutated, in the 21st century, into a corporate regime of knowledge extractivism and epistemic colonialism.2 this is unsurprising, since machine learning algorithms are the most powerful algorithms for information compression.the purpose of the nooscope map is to secularize ai from the ideological status of ‘intelligent machine’ to one of knowledge instrument. rather than evoking legends of alien cognition, it is more reasonable to consider machine learning as an instrument of knowledge magnification that helps to perceive features, patterns, and correlations through vast spaces of data beyond human reach. in the history of science and technology, this is no news: it has already been pursued by optical instruments throughout the histories of astronomy and medicine.3 in the tradition of science, machine learning is just a nooscope, an instrument to see and navigate the space of knowledge (from the greek skopein ‘to examine, look’ and noos ‘knowledge’).borrowing the idea from gottfried wilhelm leibniz, the nooscope diagram applies the analogy of optical media to the structure of all machine learning apparatuses. discussing the power of his calculus ratiocinator and ‘characteristic numbers’ (the idea to design a numerical universal language to codify and solve all the problems of human reasoning), leibniz made an analogy with instruments of visual magnification such as the microscope and telescope. he wrote: ‘once the characteristic numbers are established for most concepts, mankind will then possess a new instrument which will enhance the capabilities of the mind to a far greater extent than optical instruments strengthen the eyes, and will supersede the microscope and telescope to the same extent that reason is superior to eyesight.’4 although the purpose of this text is not to reiterate the opposition between quantitative and qualitative cultures, leibniz’s credo need not be followed. controversies cannot be conclusively computed. machine learning is not the ultimate form of intelligence.instruments of measurement and perception always come with inbuilt aberrations. in the same way that the lenses of microscopes and telescopes are never perfectly curvilinear and smooth, the logical lenses of machine learning embody faults and biases. to understand machine learning and register its impact on society is to study the degree by which social data are diffracted and distorted by these lenses. this is generally known as the debate on bias in ai, but the political implications of the logical form of machine learning are deeper. machine learning is not bringing a new dark age but one of diffracted rationality, in which, as it will be shown, an episteme of causation is replaced by one of automated correlations. more in general, ai is a new regime of truth, scientific proof, social normativity and rationality, which often does take the shape of a statistical hallucination. this diagram manifesto is another way to say that ai, the king of computation (patriarchal fantasy of mechanised knowledge, ‘master algorithm’ and alpha machine) is naked. here, we are peeping into its black box.on the the invention of metaphors as instrument of knowledge magnification. emanuele tesauro, il canocchiale aristotelico [the aristotelian telescope], frontispiece of the 1670 edition, turin.the history of ai is a history of experiments, machine failures, academic controversies, epic rivalries around military funding, popularly known as ‘winters of ai.’5 although corporate ai today describes its power with the language of ‘black magic’ and ‘superhuman cognition’, current techniques are still at the experimental stage.6 ai is now at the same stage as when the steam engine was invented, before the laws of thermodynamics necessary to explain and control its inner workings, had been discovered. similarly, today, there are efficient neural networks for image recognition, but there is no theory of learning to explain why they work so well and how they fail so badly. like any invention, the paradigm of machine learning consolidated slowly, in this case through the last half-century. a master algorithm has not appeared overnight. rather, there has been a gradual construction of a method of computation that still has to find a common language. manuals of machine learning for students, for instance, do not yet share a common terminology. how to sketch, then, a critical grammar of machine learning that may be concise and accessible, without playing into the paranoid game of defining general intelligence?as an instrument of knowledge, machine learning is composed of an object to be observed (training dataset), an instrument of observation (learning algorithm) and a final representation (statistical model). the assemblage of these three elements is proposed here as a spurious and baroque diagram of machine learning, extravagantly termed nooscope.7 staying with the analogy of optical media, the information flow of machine learning is like a light beam that is projected by the training data, compressed by the algorithm and diffracted towards the world by the lens of the statistical model.the nooscope diagram aims to illustrate two sides of machine learning at the same time: how it works and how it fails — enumerating its main components, as well as the broad spectrum of errors, limitations, approximations, biases, faults, fallacies and vulnerabilities that are native to its paradigm.8 this double operation stresses that ai is not a monolithic paradigm of rationality but a spurious architecture made of adapting techniques and tricks. besides, the limits of ai are not simply technical but are imbricated with human bias. in the nooscope diagram the essential components of machine learning are represented at the centre, human biases and interventions on the left, and technical biases and limitations on the right. optical lenses symbolize biases and approximations representing the compression and distortion of the information flow. the total bias of machine learning is represented by the central lens of the statistical model through which the perception of the world is diffracted.the limitations of ai are generally perceived today thanks to the discourse on bias —the amplification of gender, race, ability, and class discrimination by algorithms. in machine learning, it is necessary to distinguish between historical bias, dataset bias, and algorithm bias, all of which occur at different stages of the information flow.9 historical bias (or world bias) is already apparent in society before technological intervention. nonetheless, the naturalisation of such bias, that is the silent integration of inequality into an apparently neutral technology is by itself harmful.10 paraphrasing michelle alexander, ruha benjamin has called it the new jim code: ‘the employment of new technologies that reflect and reproduce existing inequalities but that are promoted and perceived as more objective or progressive than the discriminatory systems of a previous era.’11dataset bias is introduced through the preparation of training data by human operators. the most delicate part of the process is data labelling, in which old and conservative taxonomies can cause a distorted view of the world, misrepresenting social diversities and exacerbating social hierarchies (see below the case of imagenet).algorithmic bias (also known as machine bias, statistical bias or model bias, to which the nooscope diagram gives particular attention) is the further amplification of historical bias and dataset bias by machine learning algorithms. the problem of bias has mostly originated from the fact that machine learning algorithms are among the most efficient for information compression, which engenders issues of information resolution, diffraction and loss.12 since ancient times, algorithms have been procedures of an economic nature, designed to achieve a result in the shortest number of steps consuming the least amount of resources: space, time, energy and labour.13 the arms race of ai companies is, still today, concerned with finding the simplest and fastest algorithms with which to capitalise data. if information compression produces the maximum rate of profit in corporate ai, from the societal point of view, it produces discrimination and the loss of cultural diversity.while the social consequences of ai are popularly understood under the issue of bias, the common understanding of technical limitations is known as the black box problem. the black box effect is an actual issue of deep neural networks (which filter information so much that their chain of reasoning cannot be reversed) but has become a generic pretext for the opinion that ai systems are not just inscrutable and opaque, but even ‘alien’ and out of control.14 the black box effect is part of the nature of any experimental machine at the early stage of development (it has already been noticed that the functioning of the steam engine remained a mystery for some time, even after having been successfully tested). the actual problem is the black box rhetoric, which is closely tied to conspiracy theory sentiments in which ai is an occult power that cannot be studied, known, or politically controlled.mass digitalisation, which expanded with the internet in the 1990s and escalated with datacentres in the 2000s, has made available vast resources of data that, for the first time in history, are free and unregulated. a regime of knowledge extractivism (then known as big data) gradually employed efficient algorithms to extract ‘intelligence’ from these open sources of data, mainly for the purpose of predicting consumer behaviours and selling ads. the knowledge economy morphed into a novel form of capitalism, called cognitive capitalism and then surveillance capitalism, by different authors.15 it was the internet information overflow, vast datacentres, faster microprocessors and algorithms for data compression that laid the groundwork for the rise of ai monopolies in the 21st century.what kind of cultural and technical object is the dataset that constitutes the source of ai? the quality of training data is the most important factor affecting the so-called ‘intelligence’ that machine learning algorithms extract. there is an important perspective to take into account, in order to understand ai as a nooscope. data is the first source of value and intelligence. algorithms are second; they are the machines that compute such value and intelligence into a model. however, training data are never raw, independent and unbiased (they are already themselves ‘algorithmic’).16 the carving, formatting and editing of training datasets is a laborious and delicate undertaking, which is probably more significant for the final results than the technical parameters that control the learning algorithm. the act of selecting one data source rather than another is the profound mark of human intervention into the domain of the ‘artificial’ minds.the training dataset is a cultural construct, not just a technical one. it usually comprises input data that are associated with ideal output data, such as pictures with their descriptions, also called labels or metadata.17 the canonical example would be a museum collection and its archive, in which artworks are organised by metadata such as author, year, medium, etc. the semiotic process of assigning a name or a category to a picture is never impartial; this action leaves another deep human imprint on the final result of machine cognition. a training dataset for machine learning is usually composed through the following steps: 1) production: labour or phenomena that produce information; 2) capture: encoding of information into a data format by an instrument: 3) formatting: organisation of data into a dataset: 4) labelling: in supervised learning, the classification of data into categories (metadata).machine intelligence is trained on vast datasets that are accumulated in ways neither technically neutral nor socially impartial. raw data does not exist, as it is dependent on human labour, personal data, and social behaviours that accrue over long periods, through extended networks and controversial taxonomies.18 the main training datasets for machine learning (nmist, imagenet, labelled faces in the wild, etc.) originated in corporations, universities, and military agencies of the global north. but taking a more careful look, one discovers a profound division of labour that innervates into the global south via crowdsourcing platforms that are used to edit and validate data.19 the parable of the imagenet dataset exemplifies the troubles of many ai datasets. imagenet is a training dataset for deep learning that has become the de facto benchmark for image recognition algorithms: indeed, the deep learning revolution started in 2012 when alex krizhevsky, ilya sutskever and geoffrey hinton won the annual imagenet challenge with the convolutional neural network alexnet.20 imagenet was initiated by computer scientist fei-fei li back in 2006.21 fei-fei li had three intuitions to build a reliable dataset for image recognition. first, to download millions of free images from web services such as flickr and google. second, to adopt the computational taxonomy wordnet for image labels.22 third, to outsource the work of labelling millions of images via the crowdsourcing platform amazon mechanical turk. at the end of the day (and of the assembly line), anonymous workers from all over the planet were paid few cents per task to label hundreds of pictures per minute according to the wordnet taxonomy: their labour resulted in the engineering of a controversial cultural construct. ai scholars kate crawford and artist trevor paglen have investigated and disclosed the sedimentation of racist and sexist categories in imagenet taxonomy: see the legitimation of the category ‘failure, loser, nonstarter, unsuccessful person’ for a hundred arbitrary pictures of people.23the voracious data extractivism of ai has caused an unforeseeable backlash on digital culture: in the early 2000s, lawrence lessig could not predict that the large repository of online images credited by creative commons licenses would a decade later become an unregulated resource for face recognition surveillance technologies. in similar ways, personal data is continually incorporated without transparency into privatised datasets for machine learning. in 2019 artist and ai researcher adam harvey for the first time disclosed the nonconsensual use of personal photos in training datasets for face recognition. harvey’s disclosure caused stanford university, duke university and microsoft to withdraw their datasets amidst a major privacy infringement scandal.24 online training datasets trigger issues of data sovereignty and civil rights that traditional institutions are slow to counteract (see the european general data protection regulation).25 if 2012 was the year in which the deep learning revolution began, 2019 was the year in which its sources were discovered to be vulnerable and corrupted.combinatorial patterns and kufic scripts, topkapi scroll, ca. 1500, iran. the need to demystify ai (at least from the technical point of view) is understood in the corporate world too. head of facebook ai and godfather of convolutional neural networks yann lecun reiterates that current ai systems are not sophisticated versions of cognition, but rather, of perception. similarly, the nooscope diagram exposes the skeleton of the ai black box and shows that ai is not a thinking automaton but an algorithm that performs pattern recognition. the notion of pattern recognition contains issues that must be elaborated upon. what is a pattern, by the way? is a pattern uniquely a visual entity? what does it mean to read social behaviours as patterns? is pattern recognition an exhaustive definition of intelligence? most likely not. to clarify these issues, it would be good to undertake a brief archaeology of ai.the archetype machine for pattern recognition is frank rosenblatt’s perceptron. invented in 1957 at cornell aeronautical laboratory in buffalo, new york, its name is a shorthand for ‘perceiving and recognizing automaton.’26 given a visual matrix of 20x20 photoreceptors, the perceptron can learn how to recognise simple letters. a visual pattern is recorded as an impression on a network of artificial neurons that are firing up in concert with the repetition of similar images and activating one single output neuron. the output neuron fires 1=true, if a given image is recognised, or 0=false, if a given image is not recognised.the automation of perception, as a visual montage of pixels along a computational assembly line, was originally implicit mcculloch and pitt’s concept of artificial neural networks.27 once the algorithm for visual pattern recognition survived the ‘winter of ai’ and proved efficient in the late 2000s, it was applied also to non-visual datasets, properly inaugurating the age of deep learning (the application of pattern recognition techniques to all kinds of data, not just visual). today, in the case of self-driving cars, the patterns that need to be recognised are objects in road scenarios. in the case of automatic translation, the patterns that need to be recognised are the most common sequences of words across bilingual texts. regardless of their complexity, from the numerical perspective of machine learning, notions such as image, movement, form, style, and ethical decision can all be described as statistical distributions of pattern. in this sense, pattern recognition has truly become a new cultural technique that is used in various fields. for explanatory purposes, the nooscope is described as a machine that operates on three modalities: training, classification, and prediction. in more intuitive terms, these modalities can be called: pattern extraction, pattern recognition, and pattern generation.rosenblatt’s perceptron was the first algorithm that paved the way to machine learning in the contemporary sense. at a time when ‘computer science’ had not yet been adopted as definition, the field was called ‘computational geometry’ and specifically ‘connectionism’ by rosenblatt himself. the business of these neural networks, however, was to calculate a statistical inference. what a neural network computes, is not an exact pattern but the statistical distribution of a pattern. just scraping the surface of the anthropomorphic marketing of ai, one finds another technical and cultural object that needs examination: the statistical model. what is the statistical model in machine learning? how is it calculated? what is the relationship between a statistical model and human cognition? these are crucial issues to clarify. in terms of the work of demystification that needs to be done (also to evaporate some naïve questions), it would be good to reformulate the trite question ‘can a machine think?’ into the theoretically sounder questions ‘can a statistical model think?’, ‘can a statistical model develop consciousness?’, et cetera.the algorithms of ai are often evoked as alchemic formulas, capable of distilling ‘alien’ forms of intelligence. but what do the algorithms of machine learning really do? few people, including the followers of agi (artificial general intelligence), bother to ask this question. algorithm is the name of a process, whereby a machine performs a calculation. the product of such machine processes is a statistical model (more accurately termed an ‘algorithmic statistical model’). in the developer community, the term ‘algorithm’ is increasingly replaced with ‘model.’ this terminological confusion arises from the fact that the statistical model does not exist separately from the algorithm: somehow, the statistical model exists inside the algorithm under the form of distributed memory across its parameters. for the same reason, it is essentially impossible to visualise an algorithmic statistical model, as is done with simple mathematical functions. still, the challenge is worthwhile.in machine learning, there are many algorithm architectures: simple perceptron, deep neural network, support vector machine, bayesian network, markov chain, autoencoder, boltzmann machine, etc. each of these architectures has a different history (often rooted in military agencies and corporations of the global north). artificial neural networks started as simple computing structures that evolved into complex ones which are now controlled by a few hyperparameters that express millions of parameters.28 for instance, convolutional neural networks are described by a limited set of hyperparameters (number of layers, number of neurons per layer, type of connection, behaviour of neurons, etc.) that project a complex topology of thousands of artificial neurons with millions of parameters in total. the algorithm starts as a blank slate and, during the process called training, or ‘learning from data', adjusts its parameters until it reaches a good representation of the input data. in image recognition, as already seen, the computation of millions of parameters has to resolve into a simple binary output: 1=true, a given image is recognised; or 0=false, a given image is not recognised.29source: www.asimovinstitute.org/neural-network-zoo attempting an accessible explanation of the relationship between algorithm and model, let’s have a look at the complex inception v3 algorithm, a deep convolutional neural network for image recognition designed at google and trained on the imagenet dataset. inception v3 is said to have a 78% accuracy in identifying the label of a picture, but the performance of ‘machine intelligence’ in this case can be measured also by the proportion between the size of training data and the trained algorithm (or model). imagenet contains 14 million images with associated labels that occupy approximately 150 gigabytes of memory. on the other hand, inception v3, which is meant to represent the information contained in imagenet, is only 92 megabytes. the ratio of compression between training data and model partially describes also the rate of information diffraction. a table from the keras documentation compares these values (numbers of parameters, layer depth, file dimension and accuracy) for the main models of image recognition.30 this is a brutalist but effective way to show the relation between model and data, to show how the ‘intelligence’ of algorithms is measured and assessed in the developer community.source: keras.io/applicationsstatistical models have always influenced culture and politics. they did not just emerge with machine learning: machine learning is just a new way to automate the technique of statistical modelling. when greta thunberg warns ‘listen to science.’ what she really means, being a good student of mathematics, is ‘listen to the statistical models of climate science.’ no statistical models, no climate science: no climate science, no climate activism. climate science is indeed a good example to start with, in order to understand statistical models. global warming has been calculated by first collecting a vast dataset of temperatures from earth’s surface each day of the year, and second, by applying a mathematical model that plots the curve of temperature variations in the past and projects the same pattern into the future.31 climate models are historical artefacts that are tested and debated within the scientific community, and today, also beyond.32 machine learning models, on the contrary, are opaque and inaccessible to community debate. given the degree of myth-making and social bias around its mathematical constructs, ai has indeed inaugurated the age of statistical science fiction. nooscope is the projector of this large statistical cinema.‘all models are wrong, but some are useful’ — the canonical dictum of the british statistician george box has long encapsulated the logical limitations of statistics and machine learning.33 this maxim, however, is often used to legitimise the bias of corporate and state ai. computer scientists argue that human cognition reflects the capacity to abstract and approximate patterns. so what’s the problem with machines being approximate, and doing the same? within this argument, it is rhetorically repeated that ‘the map is not the territory’. this sounds reasonable. but what should be contested is that ai is a heavily compressed and distorted map of the territory and that this map, like many forms of automation, is not open to community negotiation. ai is a map of the territory without community access and community consent.34how does machine learning plot a statistical map of the world? let’s face the specific case of image recognition (the basic form of the labour of perception, which has been codified and automated as pattern recognition).35 given an image to be classified, the algorithm detects the edges of an object as the statistical distribution of dark pixels surrounded by light ones (a typical visual pattern). the algorithm does not know what an image is, does not perceive an image as human cognition does, it only computes pixels, numerical values of brightness and proximity. the algorithm is programmed to record only the dark edge of a profile (that is to fit that desired pattern) and not all the pixels across the image (that would result in overfitting and repeating the whole visual field). a statistical model is said to be trained successfully when it can elegantly fit only the important patterns of the training data and apply those patterns also to new data ‘in the wild’. if a model learns the training data too well, it recognises only exact matches of the original patterns and will overlook those with close similarities, ‘in the wild’. in this case, the model is overfitting, because it has meticulously learnt everything (including noise) and is not able to distinguish a pattern from its background. on the other hand, the model is underfitting when it is not able to detect meaningful patterns from the training data. the notions of data overfitting, fitting and underfitting can be visualised on a cartesian plane.the challenge of guarding the accuracy of machine learning lays in calibrating the equilibrium between data underfitting and overfitting, which is difficult to do because of different machine biases. machine learning is a term that, as much as ‘ai', anthropomorphizes a piece of technology: machine learning learns nothing in the proper sense of the word, as a human does; machine learning simply maps a statistical distribution of numerical values and draws a mathematical function that hopefully approximates human comprehension. that being said, machine learning can, for this reason, cast new light on the ways in which humans comprehend.the statistical model of machine learning algorithms is also an approximation in the sense that it guesses the missing parts of the data graph: either through interpolation, which is the prediction of an output y within the known interval of the input x in the training dataset, or through extrapolation, which is the prediction of output y beyond the limits of x, often with high risks of inaccuracy. this is what ‘intelligence’ means today within machine intelligence: to extrapolate a non-linear function beyond known data boundaries. as dan mcquillian aptly puts it: ‘there is no intelligence in artificial intelligence, nor does it learn, even though its technical name is machine learning, it is simply mathematical minimization.’36it is important to recall that the ‘intelligence’ of machine learning is not driven by exact formulas of mathematical analysis, but by algorithms of brute force approximation. the shape of the correlation function between input x and output y is calculated algorithmically, step by step, through tiresome mechanical processes of gradual adjustment (like gradient descent, for instance) that are equivalent to the differential calculus of leibniz and newton. neural networks are said to be among the most efficient algorithms because these differential methods can approximate the shape of any function given enough layers of neurons and abundant computing resources.37 brute-force gradual approximation of a function is the core feature of today’s ai, and only from this perspective can one understand its potentialities and limitations — particularly its escalating carbon footprint (the training of deep neural networks requires exorbitant amounts of energy because of gradient descent and similar training algorithms that operate on the basis of continuous infinitesimal adjustments).38the notions of data fitting, overfitting, underfitting, interpolation and extrapolation can be easily visualised in two dimensions, but statistical models usually operate along multidimensional spaces of data. before being analysed, data are encoded into a multi-dimensional vector space that is far from intuitive. what is a vector space and why is it multi-dimensional? cardon, cointet and mazière describe the vectorialisation of data in this way:a neural network requires the inputs of the calculator to take on the form of a vector. therefore, the world must be coded in advance in the form of a purely digital vectorial representation. while certain objects such as images are naturally broken down into vectors, other objects need to be ‘embedded’ within a vectorial space before it is possible to calculate or classify them with neural networks. this is the case of text, which is the prototypical example. to input a word into a neural network, the word2vec technique ‘embeds’ it into a vectorial space that measures its distance from the other words in the corpus. words thus inherit a position within a space with several hundreds of dimensions. the advantage of such a representation resides in the numerous operations offered by such a transformation. two terms whose inferred positions are near one another in this space are equally similar semantically; these representations are said to be distributed: the vector of the concept ‘apartment’ [-0.2, 0.3, -4.2, 5.1...] will be similar to that of ‘house’ [-0.2, 0.3, -4.0, 5.1...]. […] while natural language processing was pioneering for ‘embedding’ words in a vectorial space, today we are witnessing a generalization of the embedding process which is progressively extending to all applications fields: networks are becoming simple points in a vectorial space with graph2vec, texts with paragraph2vec, films with movie2vec, meanings of words with sens2vec, molecular structures with mol2vec, etc. according to yann lecun, the goal of the designers of connectionist machines is to put the world in a vector (world2vec).39multi-dimensional vector space is another reason why the logic of machine learning is difficult to grasp. vector space is another new cultural technique, worth becoming familiar with. the field of digital humanities, in particular, has been covering the technique of vectorialisation through which our collective knowledge is invisibly rendered and processed. william gibson’s original definition of cyberspace prophesized, most likely, the coming of a vector space rather than virtual reality: ‘a graphic representation of data abstracted from the banks of every computer in the human system. unthinkable complexity. lines of light ranged in the nonspace of the mind, clusters and constellations of data. like city lights, receding.’40 right: vector space of seven words in three contexts.41it must be stressed, however, that machine learning still resembles more craftsmanship than exact mathematics. ai is still a history of hacks and tricks rather than mystical intuitions. for example, one trick of information compression is dimensionality reduction, which is used to avoid the curse of dimensionality, that is the exponential growth of the variety of features in the vector space. the dimensions of the categories that show low variance in the vector space (i.e. whose values fluctuate only a little) are aggregated to reduce calculation costs. dimensionality reduction can be used to cluster word meanings (such as in the model word2vec) but can also lead to category reduction, which can have an impact on the representation of social diversity. dimensionality reduction can shrink taxonomies and introduce bias, further normalising world diversity and obliterating unique identities.42most of the contemporary applications of machine learning can be described according to the two modalities of classification and prediction, which outline the contours of a new society of control and statistical governance. classification is known as pattern recognition, while prediction can be defined also as pattern generation. a new pattern is recognised or generated by interrogating the inner core of the statistical model.machine learning classification is usually employed to recognise a sign, an object, or a human face, and to assign a corresponding category (label) according to taxonomy or cultural convention. an input file (e.g. a headshot captured by a surveillance camera) is run through the model to determine whether it falls within its statistical distribution or not. if so, it is assigned the corresponding output label. since the times of the perceptron, classification has been the originary application of neural networks: with deep learning this technique is found ubiquitously in face recognition classifiers that are deployed by police forces and smartphone manufacturers alike.machine learning prediction is used to project future trends and behaviours according to past ones, that is to complete a piece of information knowing only a portion of it. in the prediction modality, a small sample of input data (a primer) is used to predict the missing part of the information following once again the statistical distribution of the model (this could be the part of a numerical graph oriented toward the future or the missing part of an image or audio file). incidentally, other modalities of machine learning exist: the statistical distribution of a model can be dynamically visualised through a technique called latent space exploration and, in some recent design applications, also pattern exploration.43machine learning classification and prediction are becoming ubiquitous techniques that constitute new forms of surveillance and governance. some apparatuses, such as self-driving vehicles and industrial robots, can be an integration of both modalities. a self-driving vehicle is trained to recognise different objects on the road (people, cars, obstacles, signs) and predict future actions based on decisions that a human driver has taken in similar circumstances. even if recognising an obstacle on a road seems to be a neutral gesture (it’s not), identifying a human being according to categories of gender, race and class (and in the recent covid-19 pandemic as sick or immune), as state institutions are increasingly doing, is the gesture of a new disciplinary regime. the hubris of automated classification has caused the revival of reactionary lombrosian techniques that were thought to have been consigned to history, techniques such as automatic gender recognition (agr), ‘a subfield of facial recognition that aims to algorithmically identify the gender of individuals from photographs or videos.’44recently, the generative modality of machine learning has had a cultural impact: its use in the production of visual artefacts has been received by mass media as the idea that artificial intelligence is ‘creative’ and can autonomously make art. an artwork that is said to be created by ai always hides a human operator, who has applied the generative modality of a neural network trained on a specific dataset. in this modality, the neural network is run backwards (moving from the smaller output layer toward the larger input layer) to generate new patterns after being trained at classifying them, a process that usually moves from the larger input layer to the smaller output layer. the generative modality, however, has some useful applications: it can be used as a sort of reality check to reveal what the model has learnt, i.e. to show how the model ‘sees the world.’ it can be applied to the model of a self-driving car, for instance, to check how the road scenario is projected.a famous way to illustrate how a statistical model ‘sees the world’ is google deepdream. deepdream is a convolutional neural network based on inception (which is trained on the imagenet dataset mentioned above) that was programmed by alexander mordvintsev to project hallucinatory patterns. mordvintsev had the idea to ‘turn the network upside down’, that is to turn a classifier into a generator, using some random noise or generic landscape images as input.45 he discovered that ‘neural networks that were trained to discriminate between different kinds of images have quite a bit of the information needed to generate images too.’ in deepdream first experiments, bird feathers and dog eyes started to emerge everywhere as dog breeds and bird species are vastly overrepresented in imagenet. it was also discovered that the category ‘dumbbell’ was learnt with a surreal human arm always attached to it. proof that many other categories of imagenet are misrepresented.the two main modalities of classification and generation can be assembled in further architectures such as in the generative adversarial networks. in the gan architecture, a neural network with the role of discriminator (a traditional classifier) has to recognise an image produced by a neural network with the role of generator, in a reinforcement loop that trains the two statistical models simultaneously. for some converging properties of their respective statistical models, gans have proved very good at generating highly realistic pictures. this ability has prompted their abuse in the fabrication of ‘deep fakes’.46 concerning regimes of truth, a similar controversial application is the use of gans to generate synthetic data in cancer research, in which neural networks trained on unbalanced datasets of cancer tissues have started to hallucinate cancer where there was none.47 in this case ‘instead of discovering things, we are inventing things', fabian offert notices, ‘the space of discovery is identical to the space of knowledge that the gan has already had. […] while we think that we are seeing through gan — looking at something with the help of a gan — we are actually seeing into a gan. gan vision is not augmented reality, it is virtual reality. gans do blur discovery and invention.’48 the gan simulation of brain cancer is a tragic example of ai-driven scientific hallucination.joseph paul cohen, margaux luck and sina honari. ‘distribution matching losses can hallucinate features in medical image translation’, 2018. courtesy of the authors.the normative power of ai in the 21st century has to be scrutinised in these epistemic terms: what does it mean to frame collective knowledge as patterns, and what does it mean to draw vector spaces and statistical distributions of social behaviours? according to foucault, in early modern france, statistical power was already used to measure social norms, discriminating between normal and abnormal behaviour.49 ai easily extends the ‘power of normalisation’ of modern institutions, among others bureaucracy, medicine and statistics (originally, the numerical knowledge possessed by the state about its population) that passes now into the hands of ai corporations. the institutional norm has become a computational one: the classification of the subject, of bodies and behaviours, seems no longer to be an affair for public registers, but instead for algorithms and datacentres.50 ‘data-centric rationality’, paula duarte has concluded, ‘should be understood as an expression of the coloniality of power.’51a gap, a friction, a conflict, however, always persists between ai statistical models and the human subject that is supposed to be measured and controlled. this logical gap between ai statistical models and society is usually debated as bias. it has been extensively demonstrated how face recognition misrepresents social minorities and how black neighbourhoods, for instance, are bypassed by ai-driven logistics and delivery service.52 if gender, race and class discriminations are amplified by ai algorithms, this is also part of a larger problem of discrimination and normalisation at the logical core of machine learning. the logical and political limitation of ai is the technology’s difficulty in the recognition and prediction of a new event. how is machine learning dealing with a truly unique anomaly, an uncommon social behaviour, an innovative act of disruption? the two modalities of machine learning display a limitation that is not simply bias.a logical limit of machine learning classification, or pattern recognition, is the inability to recognise a unique anomaly that appears for the first time, such as a new metaphor in poetry, a new joke in everyday conversation, or an unusual obstacle (a pedestrian? a plastic bag?) on the road scenario. the undetection of the new (something that has never ‘been seen’ by a model and therefore never classified before in a known category) is a particularly hazardous problem for self-driving cars and one that has already caused fatalities. machine learning prediction, or pattern generation, show similar faults in the guessing of future trends and behaviours. as a technique of information compression, machine learning automates the dictatorship of the past, of past taxonomies and behavioural patterns, over the present. this problem can be termed the regeneration of the old — the application of a homogenous space-time view that restrains the possibility of a new historical event.interestingly, in machine learning, the logical definition of a security issue also describes the logical limit of its creative potential. the problems characteristic of the prediction of the new are logically related to those that characterise the generation of the new, because the way a machine learning algorithm predicts a trend on a time chart is identical to the way it generates a new artwork from learnt patterns. the hackneyed question ‘can ai be creative?’ should be reformulated in technical terms: is machine learning able to create works that are not imitations of the past? is machine learning able to extrapolate beyond the stylistic boundaries of its training data? the ‘creativity’ of machine learning is limited to the detection of styles from the training data and then random improvisation within these styles. in other words, machine learning can explore and improvise only within the logical boundaries that are set by the training data. for all these issues, and its degree of information compression, it would be more accurate to term machine learning art as statistical art. lewis fry richardson, weather prediction by numerical process, cambridge university press, 1922.another unspoken bug of machine learning is that the statistical correlation between two phenomena is often adopted to explain causation from one to the other. in statistics, it is commonly understood that correlation does not imply causation, meaning that a statistical coincidence alone is not sufficient to demonstrate causation. a tragic example can be found in the work of statistician frederick hoffman, who in 1896 published a 330-page report for insurance companies to demonstrate a racial correlation between being a black american and having short life expectancy.53 superficially mining data, machine learning can construct any arbitrary correlation that is then perceived as real. in 2008 this logical fallacy was proudly embraced by wired director chris anderson who declared the ‘end of theory’ because ‘the data deluge makes the scientific method obsolete.’54 according to anderson, himself no expert on scientific method and logical inference, statistical correlation is enough for google to run its ads business, therefore it must also be good enough to automatically discover scientific paradigms. even judea pearl, a pioneer of bayesian networks, believes that machine learning is obsessed with ‘curve fitting’, recording correlations without providing explanations.55 such a logical fallacy has already become a political one, if one considers that police forces worldwide have adopted predictive policing algorithms.56 according to dan mcquillan, when machine learning is applied to society in this way, it turns into a biopolitical apparatus of preemption, that produces subjectivities which can subsequently be criminalized.57 ultimately, machine learning obsessed with ‘curve fitting’ imposes a statistical culture and replaces the traditional episteme of causation (and political accountability) with one of correlations blindly driven by the automation of decision making.so far the statistical diffractions and hallucinations of machine learning have been followed step by step through the multiple lenses of the nooscope. at this point, the orientation of the instrument has to be reversed: scientific theories as much as computational devices are inclined to consolidate an abstract perspective — the scientific ‘view from nowhere’, that is often just the point of view of power. the obsessive study of ai can suck the scholar into an abyss of computation and the illusion that the technical form illuminates the social one. as paola ricaurte remarks: ‘data extractivism assumes that everything is a data source.’58 how to emancipate ourselves from a data-centric view of the world? it is time to realise that it is not the statistical model that constructs the subject, but rather the subject that structures the statistical model. internalist and externalist studies of ai have to blur: subjectivities make the mathematics of control from within, not from without. to second what guattari once said of machines in general, machine intelligence too is constituted of ‘hyper-developed and hyper-concentrated forms of certain aspects of human subjectivity.’59rather than studying only how technology works, critical inquiry studies also how it breaks, how subjects rebel against its normative control and workers sabotage its gears. in this sense, a way to sound the limits of ai is to look at hacking practices. hacking is an important method of knowledge production, a crucial epistemic probe into the obscurity of ai.60 deep learning systems for face recognition have triggered, for instance, forms of counter-surveillance activism. through techniques of face obfuscation, humans have decided to become unintelligible to artificial intelligence: that is to become, themselves, black boxes. the traditional techniques of obfuscation against surveillance immediately acquire a mathematical dimension in the age of machine learning. for example, ai artist and researcher adam harvey has invented a camouflage textile called hyperface that fools computer vision algorithms to see multiple human faces where there is none.61 harvey's work provokes the question: what constitutes a face for a human eye, on the one hand, and a computer vision algorithm, on the other? the neural glitches of hyperface exploit such a cognitive gap and reveal what a human face looks like to a machine. this gap between human and machine perception helps to introduce the growing field of adversarial attacks.adam harvey, hyperface pattern, 2016.adversarial attacks exploit blind spots and weak regions in the statistical model of a neural network, usually to fool a classifier and make it perceive something that is not there. in object recognition, an adversarial example can be a doctored image of a turtle, which looks innocuous to a human eye but gets misclassified by a neural network as a rifle.62 adversarial examples can be realised as 3d objects and even stickers for road signs that can misguide self-driving cars (which may read a speed limit of 120 km/h where it is actually 50 km/h).63 adversarial examples are designed knowing what a machine has never seen before. this effect is achieved also by reverse-engineering the statistical model or by polluting the training dataset. in this latter sense, the technique of data poisoning targets the training dataset and introduces doctored data. in so doing it alters the accuracy of the statistical model and creates a backdoor that can be eventually exploited by an adversarial attack.64adversarial attack seems to point to a mathematical vulnerability that is common to all machine learning models: ‘an intriguing aspect of adversarial examples is that an example generated for one model is often misclassified by other models, even when they have different architectures or were trained on disjoint training sets.’65 adversarial attacks remind us of the discrepancy between human and machine perception and that the logical limit of machine learning is also a political one. the logical and ontological boundary of machine learning is the unruly subject or anomalous event that escapes classification and control. the subject of algorithmic control fires back. adversarial attacks are a way to sabotage the assembly line of machine learning by inventing a virtual obstacle that can set the control apparatus out of joint. an adversarial example is the sabot in the age of ai.the natures of the ‘input’ and ‘output’ of machine learning have to be clarified. ai troubles are not only about information bias but also labour. ai is not just a control apparatus, but also a productive one. as just mentioned, an invisible workforce is involved in each step of its assembly line (dataset composition, algorithm supervision, model evaluation, etc.). pipelines of endless tasks innervate from the global north into the global south; crowdsourced platforms of workers from venezuela, brazil and italy, for instance, are crucial in order to teach german self-driving cars ‘how to see.’66 against the idea of alien intelligence at work, it must be stressed that in the whole computing process of ai the human worker has never left the loop, or put more accurately, has never left the assembly line. mary gray and siddharth suri coined the term ‘ghost work’ for the invisible labour that makes ai appear artificially autonomous.beyond some basic decisions, today’s artificial intelligence can’t function without humans in the loop. whether it’s delivering a relevant newsfeed or carrying out a complicated texted-in pizza order, when the artificial intelligence (ai) trips up or can’t finish the job, thousands of businesses call on people to quietly complete the project. this new digital assembly line aggregates the collective input of distributed workers, ships pieces of projects rather than products, and operates across a host of economic sectors at all times of the day and night.automation is a myth; because machines, including ai, constantly call for human help, some authors have suggested replacing ‘automation’ with the more accurate term heteromation.67 heteromation means that the familiar narrative of ai as perpetuum mobile is possible only thanks to a reserve army of workers.yet there is a more profound way in which labour constitutes ai. the information source of machine learning (whatever its name: input data, training data or just data) is always a representation of human skills, activities and behaviours, social production at large. all training datasets are, implicitly, a diagram of the division of human labour that ai has to analyse and automate. datasets for image recognition, for instance, record the visual labour that drivers, guards, and supervisors usually perform during their tasks. even scientific datasets rely on scientific labour, experiment planning, laboratory organisation, and analytical observation. the information flow of ai has to be understood as an apparatus designed to extract ‘analytical intelligence’ from the most diverse forms of labour and to transfer such intelligence into a machine (obviously including, within the definition of labour, extended forms of social, cultural and scientific production).68 in short, the origin of machine intelligence is the division of labour and its main purpose is the automation of labour.historians of computation have already stressed the early steps of machine intelligence in the 19th century project of mechanizing the division of mental labour, specifically the task of hand calculation.69 the enterprise of computation has since then been a combination of surveillance and disciplining of labour, of optimal calculation of surplus-value, and planning of collective behaviours.70 computation was established by and still enforces a regime of visibility and intelligibility, not just of logical reasoning. the genealogy of ai as an apparatus of power is confirmed today by its widespread employment in technologies of identification and prediction, yet the core anomaly which always remains to be computed is the disorganisation of labour.as a technology of automation, ai will have a tremendous impact on the job market. if deep learning has a 1% error rate in image recognition, for example, it means that roughly 99% of routine work based on visual tasks (e.g. airport security) can be potentially replaced (legal restrictions and trade union opposition permitting). the impact of ai on labour is well described (from the perspective of workers, finally) within a paper from the european trade union institute, which highlights ‘seven essential dimensions that future regulation should address in order to protect workers: 1) safeguarding worker privacy and data protection; 2) addressing surveillance, tracking and monitoring; 3) making the purpose of ai algorithms transparent; 4) ensuring the exercise of the ‘right to explanation’ regarding decisions made by algorithms or machine learning models; 5) preserving the security and safety of workers in human-machine interactions; 6) boosting workers’ autonomy in human–machine interactions; 7) enabling workers to become ai literate.’71 ultimately, the nooscope manifests for a novel machinery question in the age of ai. the machinery question was a debate that sparked in england during the industrial revolution, when the response to the employment of machines and workers’ subsequent technological unemployment was a social campaign for more education about machines, that took the form of the mechanics’ institute movement.72 today an intelligent machinery question is needed to develop more collective intelligence about ‘machine intelligence,’ more public education instead of ‘learning machines’ and their regime of knowledge extractivism (which reinforces old colonial routes, just by looking at the network map of crowdsourcing platforms today). also in the global north, this colonial relationship between corporate ai and the production of knowledge as a common good has to be brought to the fore. the nooscope’s purpose is to expose the hidden room of the corporate mechanical turk and to illuminate the invisible labour of knowledge that makes machine intelligence appear ideologically alive. on the autonomy of technology see: langdon winner, autonomous technology: technics-out-of-control as a theme in political thought. cambridge, ma: mit press, 2001. for the extension of colonial power into the operations of logistics, algorithms and finance see: sandro mezzadra and brett neilson, the politics of operations: excavating contemporary capitalism. durham: duke university press, 2019. on the epistemic colonialism of ai see: matteo pasquinelli, ‘three thousand years of algorithmic rituals.’ e-flux 101, 2019. digital humanities term a similar technique distant reading, which has gradually involved data analytics and machine learning in literary and art history. see: franco moretti, distant reading. london: verso, 2013. gottfried w. leibniz, ‘preface to the general science’, 1677. in: phillip wiener (ed.) leibniz selections. new york: scribner, 1951, 23. for a concise history of ai see: dominique cardon, jean-philippe cointet and antoine mazières, ‘neurons spike back: the invention of inductive machines and the artificial intelligence controversy.’ réseaux 211, 2018. alexander campolo and kate crawford, ‘enchanted determinism: power without control in artificial intelligence.’ engaging science, technology, and society 6, 2020. the use of the visual analogy is also intended to record the fading distinction between image and logic, representation and inference, in the technical composition of ai. the statistical models of machine learning are operative representations (in the sense of harun farocki’s operative images). for a systematic study of the logical limitations of machine learning see: momin mailk, ‘a hierarchy of limitations in machine learning.’ arxiv preprint, 2020. https://arxiv.org/abs/2002.05193 for a more detailed list of ai biases see: john guttag and harini suresh, ‘a framework for understanding unintended consequences of machine learning.’ arxiv preprint, 2019. https://arxiv.org/abs/1901.10002 see also: aram galstyan, kristin lerman, ninareh mehrabi, fred morstatter and nripsuta saxena, ‘a survey on bias and fairness in machine learning.’ arxiv preprint, 2019. https://arxiv.org/abs/1908.09635 virginia eubanks, automating inequality. new york: st. martin’s press, 2018. see also: kate crawford, ‘the trouble with bias.’ keynote lecture, conference on neural information processing systems, 2017. ruha benjamin, race after technology: abolitionist tools for the new jim code. cambridge, uk: polity, 2019, 5. computer scientists argue that ai belongs to a subfield of signal processing, that is data compression. matteo pasquinelli, the eye of the master. london: verso, forthcoming. projects such as explainable artificial intelligence, interpretable deep learning and heatmapping among others have demonstrated that breaking into the ‘black box’ of machine learning is possible. nevertheless, the full interpretability and explicability of machine learning statistical models remains a myth. see: zacharay lipton, ‘the mythos of model interpretability.’ arxiv preprint, 2016. https://arxiv.org/abs/1606.03490 a. corsani, b. paulré, c. vercellone, j.m. monnier, m. lazzarato, p. dieuaide and y. moulier-boutang, ‘le capitalisme cognitif comme sortie de la crise du capitalisme industriel. un programme de recherché’, paris: laboratoire isys matisse, maison des sciences economiques, 2004. see also: zuboff, shoshana, the age of surveillance capitalism: the fight for a human future at the new frontier of power. london: profile books, 2019. lisa gitelman (ed.), raw data is an oxymoron, cambridge, ma: mit press, 2013. in supervised learning. also self-supervised learning maintains forms of human intervention. on taxonomy as a form of knowledge and power see: michel foucault, the order of things. london: routledge, 2005. such as amazon mechanical turk, cynically termed ‘artificial artificial intelligence’ by jeff bezos. see: jason pontin, ‘artificial intelligence, with help from the humans.’ the new york times, 25 march 2007. although the convolutional architecture dates back to yann lecunn’s work in the late 1980s, deep learning starts with this paper: geoffrey hinton, alex krizhevsky and ilya sutskever, ‘imagenet classification with deep convolutional neural networks.’ communications of the acm 60(6), 2017. for an accessible (yet not very critical) account of the imagenet development see: melanie mitchell, artificial intelligence: a guide for thinking humans. london: penguin, 2019. wordnet is ‘a lexical database of semantic relations between words’ which was initiated by george armitage at princeton university in 1985. it provides a strict tree-like structure of definitions. kate crawford and trevor paglen, ‘excavating ai: the politics of training sets for machine learning.’ 19 september 2019. https://excavating.ai adam harvey and jules laplace, megapixel project, 2019. https://megapixels.cc/about/ and: madhumita murgia, ‘who's using your face? the ugly truth about facial recognition.’ financial times, 19 april 2019. the gdpr data privacy regulation that was passed by the european parliament in may 2018 is, however, an improvement compared to the regulation that is missing in the united states. frank rosenblatt, ‘the perceptron: a perceiving and recognizing automaton.’ cornell aeronautical laboratory report 85-460-1, 1957. warren mcculloch and walter pitts, ‘how we know universals: the perception of auditory and visual forms.’ the bulletin of mathematical biophysics 9(3): 1947. the parameters of a model that are learnt from data are called ‘parameters’, while parameters that are not learnt from data and are fixed manually are called ‘hyperparameters’ (these determine number and properties of the parameters). this value can be also a percentage value between 1 and 0. https://keras.io/applications (documentation for individual models). paul edwards, a vast machine: computer models, climate data, and the politics of global warming. cambridge, ma: see the the community earth system model (cesm) that has been developed by the national center for atmospheric research in bolder, colorado, since 1996. the community earth system model is a fully coupled numerical simulation of the earth system consisting of atmospheric, ocean, ice, land surface, carbon cycle, and other components. cesm includes a climate model providing state-of-the-art simulations of the earth's past, present, and future.’ http://www.cesm.ucar.edu george box, ‘robustness in the strategy of scientific model building.’ technical report #1954, mathematics research center, university of wisconsin-madison, 1979. post-colonial and post-structuralist schools of anthropology and ethnology have stressed that there is never territory per se, but always an act of territorialisation. pattern recognition is one among many other economies of attention. ‘to look is to labor’, as jonathan beller reminds us. jonathan beller, the cinematic mode of production: attention economy and the society of the spectacle. lebanon, nh: university press of new england, 2006, 2. dan mcquillan, ‘manifesto on algorithmic humanitarianism.’ presented at the symposium reimagining digital humanitarianism, goldsmiths, university of london, february 16, 2018. as proven by the universal approximation theorem. ananya ganesh, andrew mccallum and emma strubell, ‘energy and policy considerations for deep learning in nlp.’ arxiv preprint, 2019. https://arxiv.org/abs/1906.02243 cardon et al, ‘neurons spike back.’ william gibson, neuromancer. new york: ace books, 1984, 69. source: corpling.hypotheses.org/495 jamie morgenstern, samira samadi, mohit singh, uthaipon tantipongpipat and santosh vempala, ‘the price of fair pca: one extra dimension.’ advances in neural information processing systems 31, 2018. see the idea of assisted and generative creation in: roelof pieters and samim winiger, ‘creative ai: on the democratisation and escalation of creativity’, 2016. http://www. medium.com/@creativeai/creativeai-9d4b2346faf3 os keyes, ‘the misgendering machines: trans/hci implications of automatic gender recognition.’ proceedings of the acm on human-computer interaction 2(88), november 2018. https://doi.org/10.1145/3274357 alexander mordvintsev, christophe olah and mike tyka, ‘inceptionism: going deeper into neural networks.’ google research blog, june 17, 2015. https://ai.googleblog.com/2015/06/ inceptionism-going-deeper-into-neural.html deep fakes are synthetic media like videos in which a person's face is replaced with someone else's facial features, often for the purpose to forge fake news. joseph paul cohen, sina honari and margaux luck, ‘distribution matching losses can hallucinate features in medical image translation.’ international conference on medical image computing and computer-assisted intervention. cham: springer, 2018. arxiv:1805.08841 fabian offert, neural network cultures panel, transmediale festival and kim hfg karlsruhe. berlin, 1 february 2020. http://kim.hfg-karlsruhe.de/events/neural-network-cultures michel foucault, abnormal: lectures at the collège de france 1974-1975. new york: picador, 2004, 26. on computational norms see: matteo pasquinelli, ‘arcana mathematica imperii: the evolution of western computational norms.’ in: maria hlavajova et al. (eds), former west. cambridge, ma: mit press, 2017. paola ricaurte, ‘data epistemologies, the coloniality of power, and resistance.’ television & new media, 7 march 2019. david ingold, and spencer soper, ‘amazon doesn’t consider the race of its customers. should it?’, bloomberg, 21 april 2016. https://www.bloomberg.com/graphics/2016-amazon-same-day cathy o’neil, weapons of math destruction. new york: broadway books, 2016, ch 9. chris anderson, ‘the end of theory: the data deluge makes the scientific method obsolete.’ wired, 23 june 2008. for a critique see: fulvio mazzocchi, ‘could big data be the end of theory in science? a few remarks on the epistemology of data-driven science.’ embo reports 16(10), 2015. judea pearl and dana mackenzie, the book of why: the new science of cause and effect. new york: basic books, 2018. experiments by the new york police department since the late 1980s. see: pasquinelli, ‘arcana mathematica imperii.’ dan mcquillan, ‘people’s councils for ethical machine learning.’ social media and society 4(2), 2018. ricaurte, ‘data epistemologies.’ felix guattari, schizoanalytic cartographies. london: continuum, 2013, 2. the relationship between ai and hacking is not as antagonistic as it may appear: it often resolves in a loop of mutual learning, evaluation and reinforcement. adam harvey, hyperface project, 2016. https://ahprojects.com/hyperface anish athalye et al., ‘synthesizing robust adversarial examples.’ arxiv preprint, 2017. https://arxiv.org/abs/1707.07397 nir morgulis et al., ‘fooling a real car with adversarial traffic signs.’ arxiv preprint, 2019. https://arxiv.org/abs/1907.00374 data poisoning can also be employed to protect privacy by entering anonymized or random information into the dataset. ian goodfellow et al., ‘explaining and harnessing adversarial examples.’ arxiv preprint, 2014. https://arxiv.org/abs/1412.6572 florian schmidt, ‘crowdsourced production of ai training data: how human workers teach self-driving cars to see.’ düsseldorf: hans-böckler-stiftung, 2019. hamid ekbia and bonnie nardi, heteromation, and other stories of computing and capitalism. cambridge, ma: mit press, 2017. for the idea of analytical intelligence see: lorraine daston, ‘calculation and the division of labour 1750–1950.’ bulletin of the german historical institute 62, 2018. simon schaffer, ‘babbage’s intelligence: calculating engines and the factory system’, critical inquiry 21, 1994. lorraine daston, ‘enlightenment calculations’. critical inquiry 21, 1994. matthew l. jones, reckoning with matter: calculating machines, innovation, and thinking about thinking from pascal to babbage. chicago: university of chicago press, 2016. 62, 2018. matteo pasquinelli, ‘on the origins of marx’s general intellect.’ radical philosophy 2.06, 2019. aida ponce, ‘labour in the age of ai: why regulation is needed to protect workers.’ etui research paper - foresight brief 8, 2020. http://dx.doi.org/10.2139/ssrn.3541002 maxine berg, the machinery question and the making of political economy. cambridge, uk: cambridge university press, 1980. in fact, even the economist has recently warned about ‘the return of the machinery question’ in the age of ai. see: tom standage, ‘the return of the machinery question.’ the economist, 23 june 2016. diagram pdf essay pdf authors: vladan joler and matteo pasquinellivladan joler is professor at the academy of arts of the university of novi sad and founder of share foundation. he is leading share lab, a research and investigation lab that explores the technical and social aspects of algorithmic transparency, digital labor exploitation, invisible infrastructures, and technological black boxes.matteo pasquinelli is professor in media philosophy at the karlsruhe university of arts and design, where he is coordinating the research group on artificial intelligence and media philosophy kim. for verso books he is preparing a monograph on the history of ai provisionally titled the eye of the master.full citation: matteo pasquinelli and vladan joler, “the nooscope manifested: artificial intelligence as instrument of knowledge extractivism”, visual essay, kim hfg karlsruhe and share lab, 1 may 2020. http://nooscope.aiemail: input [at] nooscope.aiacknowledgements: thanks to jon beller, kate crawford, dubravko ćulibrk, ariana dongus, claire glanois, adam harvey, leonardo impett, arif kornweitz, wietske maas, dan mcquillan, fabian offert, godofredo pereira, johannes paul raether, natascha sadr haghighian, olivia solis, mitch speed and the extended community around kim hfg karlsruhe for their inputs and comments.\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de caracteres en el texto: 69986\n"
     ]
    }
   ],
   "source": [
    "print(\"Cantidad de caracteres en el texto:\", len(text_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_2 = nltk.sent_tokenize(text_2)\n",
    "words_2 = nltk.word_tokenize(text_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['download diagram pdf and essay pdf by vladan joler and matteo pasquinelli (2020) the nooscope is a cartography of the limits of artificial intelligence, intended as a provocation to both computer science and the humanities.',\n",
       " 'any map is a partial perspective, a way to provoke debate.',\n",
       " 'similarly, this map is a manifesto — of ai dissidents.',\n",
       " 'its main purpose is to challenge the mystifications of artificial intelligence.',\n",
       " 'first, as a technical definition of intelligence and, second, as a political form that would be autonomous from society and the human.']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_2[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['download',\n",
       " 'diagram',\n",
       " 'pdf',\n",
       " 'and',\n",
       " 'essay',\n",
       " 'pdf',\n",
       " 'by',\n",
       " 'vladan',\n",
       " 'joler',\n",
       " 'and',\n",
       " 'matteo',\n",
       " 'pasquinelli',\n",
       " '(',\n",
       " '2020',\n",
       " ')',\n",
       " 'the',\n",
       " 'nooscope',\n",
       " 'is',\n",
       " 'a',\n",
       " 'cartography',\n",
       " 'of',\n",
       " 'the',\n",
       " 'limits',\n",
       " 'of',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " ',',\n",
       " 'intended',\n",
       " 'as',\n",
       " 'a']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_2[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulario: 12227\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulario:\", len(words_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\FACULTAD\\ESPECIALIZACIÓN\\4. CUARTO BIMESTRE\\NLP\\env\\lib\\site-packages\\gradio\\deprecation.py:40: UserWarning: `layout` parameter is deprecated, and it has no effect\n",
      "  warnings.warn(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"900\" height=\"500\" allow=\"autoplay; camera; microphone;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: layers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\FACULTAD\\ESPECIALIZACIÓN\\4. CUARTO BIMESTRE\\NLP\\env\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: in this modality, the neural network is run backwards (moving from the smaller output layer toward the larger input layer) to generate new patterns after being trained at classifying them, a process that usually moves from the larger input layer to the smaller output layer.\n",
      "Q: ethics\n",
      "A: I am sorry, I could not understand you\n",
      "Q: ethic\n",
      "A: I am sorry, I could not understand you\n",
      "Q: black boxes\n",
      "A: through techniques of face obfuscation, humans have decided to become unintelligible to artificial intelligence: that is to become, themselves, black boxes.\n",
      "Q: nooscope\n",
      "A: there is an important perspective to take into account, in order to understand ai as a nooscope.\n",
      "Q: nooscope diagram\n",
      "A: similarly, the nooscope diagram exposes the skeleton of the ai black box and shows that ai is not a thinking automaton but an algorithm that performs pattern recognition.\n",
      "Q: algorithm\n",
      "A: but what do the algorithms of machine learning really do?\n",
      "Q: hallucination\n",
      "A: more in general, ai is a new regime of truth, scientific proof, social normativity and rationality, which often does take the shape of a statistical hallucination.\n",
      "Q: truth\n",
      "A: more in general, ai is a new regime of truth, scientific proof, social normativity and rationality, which often does take the shape of a statistical hallucination.\n",
      "Q: rethoric\n",
      "A: I am sorry, I could not understand you\n",
      "Q: rhetoric\n",
      "A: the actual problem is the black box rhetoric, which is closely tied to conspiracy theory sentiments in which ai is an occult power that cannot be studied, known, or politically controlled.mass digitalisation, which expanded with the internet in the 1990s and escalated with datacentres in the 2000s, has made available vast resources of data that, for the first time in history, are free and unregulated.\n",
      "Q: extractivism\n",
      "A: as paola ricaurte remarks: ‘data extractivism assumes that everything is a data source.’58 how to emancipate ourselves from a data-centric view of the world?\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def bot_response(human_text):\n",
    "    print(\"Q:\", human_text)    \n",
    "    resp = generate_response(human_text.lower(), corpus)\n",
    "    print(\"A:\", resp)\n",
    "    return resp\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=bot_response,\n",
    "    inputs=[\"textbox\"],\n",
    "    outputs=\"text\",\n",
    "    layout=\"vertical\")\n",
    "\n",
    "iface.launch(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2c - bot_tfidf_nltk.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
