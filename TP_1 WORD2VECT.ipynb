{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ue5hxxkdAQJg"
   },
   "source": [
    "<img src=\"https://github.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/raw/main/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
    "\n",
    "\n",
    "# Procesamiento de lenguaje natural\n",
    "## Word2vect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "kCED1hh-Ioyf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "PUbfVnzIIoMj"
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * (np.linalg.norm(b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DMOa4JPSCJ29"
   },
   "source": [
    "### Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "RIO7b8GjAC17"
   },
   "outputs": [],
   "source": [
    "corpus = np.array(['que dia es hoy', 'martes el dia de hoy es martes', 'martes muchas gracias'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8WqdaTmO8P1r"
   },
   "source": [
    "Documento 1 --> que dia es hoy \\\n",
    "Documento 2 --> martes el dia de hoy es martes \\\n",
    "Documento 3 --> martes muchas gracias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FVHxBRNzCMOS"
   },
   "source": [
    "### 1 - Obtener el vocabulario del corpus (los términos utilizados)\n",
    "- Cada documento transformarlo en una lista de términos\n",
    "- Armar un vector de términos no repetidos de todos los documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "3ZqTOZzDI7uv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La lista de documentos es: [list(['que', 'dia', 'es', 'hoy'])\n",
      " list(['martes', 'el', 'dia', 'de', 'hoy', 'es', 'martes'])\n",
      " list(['martes', 'muchas', 'gracias'])]\n",
      "****************************************************************************************************\n",
      "el vector de términos únicos es: ['que' 'de' 'es' 'gracias' 'hoy' 'el' 'dia' 'muchas' 'martes']\n"
     ]
    }
   ],
   "source": [
    "corpus = corpus.reshape(3,1)\n",
    "docu =[]\n",
    "\n",
    "for doc in corpus:\n",
    "    for i in doc:\n",
    "        term = str(i)\n",
    "        term = term.split(' ')\n",
    "        docu.append(term)\n",
    "\n",
    "docu = np.array((docu), dtype = object)\n",
    "print(f'La lista de documentos es: {docu}')\n",
    "print(100* '*')\n",
    "\n",
    "flatten_terms = [element for sublist in docu for element in sublist]\n",
    "terms = set(flatten_terms)\n",
    "\n",
    "unique_terms = []\n",
    "\n",
    "for i in terms:\n",
    "    unique_terms.append(i)\n",
    "\n",
    "vocab = np.array(unique_terms)\n",
    "print(f'el vector de términos únicos es: {vocab}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RUhH983FI7It"
   },
   "source": [
    "### 2- OneHot encoding\n",
    "Data una lista de textos, devolver una matriz con la representación oneHotEncoding de estos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "id": "Os0AAQo6I6Z1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El index para cada término del vocabulario es: {'que': 0, 'de': 1, 'es': 2, 'gracias': 3, 'hoy': 4, 'el': 5, 'dia': 6, 'muchas': 7, 'martes': 8}\n",
      "los términos del documento son: ['que', 'dia', 'es', 'hoy']\n",
      "Los indexes de los términos del documento son: [0, 6, 2, 4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 0, 1, 0, 1, 0, 1, 0, 0]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "def ohe(doc, vocab):\n",
    "    \n",
    "    words_index={}\n",
    "    \n",
    "    for word in vocab:\n",
    "        word_no_punctuation = word.strip(string.punctuation)\n",
    "        words_index[word_no_punctuation] = len(words_index)\n",
    "    print(f'El index para cada término del vocabulario es: {words_index}')\n",
    "    \n",
    "    integer_encoded =[words_index[words] for words in doc]\n",
    "    print(f'los términos del documento son: {doc}')\n",
    "    print(f'Los indexes de los términos del documento son: {integer_encoded}')\n",
    "    \n",
    "    letter = [0 for _ in range(len(words_index))]\n",
    "    \n",
    "    for value in integer_encoded:\n",
    "        letter[value] = 1\n",
    "        \n",
    "    return letter\n",
    "\n",
    "ohe(docu[0], vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IIyWGmCpJVQL"
   },
   "source": [
    "### 3- Vectores de frecuencia\n",
    "Data una lista de textos, devolver una matriz con la representación de frecuencia de estos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "id": "yqij_7eHJbUi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El index para cada término del vocabulario es: {'que': 0, 'de': 1, 'es': 2, 'gracias': 3, 'hoy': 4, 'el': 5, 'dia': 6, 'muchas': 7, 'martes': 8}\n",
      "los términos del documento son: ['martes', 'el', 'dia', 'de', 'hoy', 'es', 'martes']\n",
      "Los indexes de los términos del documento son: [8, 5, 6, 1, 4, 2, 8]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 0, 1, 1, 1, 0, 2]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def frequency(doc, vocab):\n",
    "    \n",
    "    words_index={}\n",
    "    \n",
    "    for word in vocab:\n",
    "        word_no_punctuation = word.strip(string.punctuation)\n",
    "        words_index[word_no_punctuation] = len(words_index)\n",
    "    print(f'El index para cada término del vocabulario es: {words_index}')\n",
    "    \n",
    "    integer_encoded =[words_index[words] for words in doc]\n",
    "    print(f'los términos del documento son: {doc}')\n",
    "    print(f'Los indexes de los términos del documento son: {integer_encoded}')\n",
    "    \n",
    "    letter = [0 for _ in range(len(words_index))]\n",
    "    \n",
    "    for value in integer_encoded:\n",
    "        letter[value] = Counter(integer_encoded)[value]\n",
    "        \n",
    "    return letter\n",
    "\n",
    "frequency(docu[1], vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z_Ot8HvWJcBu"
   },
   "source": [
    "### 4- TF-IDF\n",
    "Data una lista de textos, devolver una matriz con la representacion TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "id": "waG_oWtpJjRw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf: [[1. 0. 1. 0. 1. 0. 1. 0. 0.]\n",
      " [0. 1. 1. 0. 1. 1. 1. 0. 2.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 1. 1.]]\n",
      "idf: [0.47712125 0.47712125 0.17609126 0.47712125 0.17609126 0.47712125\n",
      " 0.17609126 0.47712125 0.17609126]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.47712125, 0.        , 0.17609126, 0.        , 0.17609126,\n",
       "        0.        , 0.17609126, 0.        , 0.        ],\n",
       "       [0.        , 0.47712125, 0.17609126, 0.        , 0.17609126,\n",
       "        0.47712125, 0.17609126, 0.        , 0.35218252],\n",
       "       [0.        , 0.        , 0.        , 0.47712125, 0.        ,\n",
       "        0.        , 0.        , 0.47712125, 0.17609126]])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def TF_IDF(docus, vocab):\n",
    "    \n",
    "    ohe_docs = np.zeros([docus.size,len(vocab)])\n",
    "    freq_docs = np.zeros([docus.size,len(vocab)])\n",
    "    \n",
    "    for i in range(len(docus)):\n",
    "        ohe_docs[i,:] = ohe(docu[i], vocab)\n",
    "        freq_docs[i,:] = frequency(docu[i], vocab)\n",
    "    \n",
    "    appear = np.sum(ohe_docs, axis= 0)\n",
    "    \n",
    "    idf = np.log10(docus.size/appear)\n",
    "    tf = freq_docs\n",
    "    print(f'tf: {tf}')\n",
    "    print(f'idf: {idf}')\n",
    "    \n",
    "    tf_idf = tf*idf\n",
    "    return tf_idf\n",
    "\n",
    "TF_IDF(docu, vocab)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xMcsfndWJjm_"
   },
   "source": [
    "### 5 - Comparación de documentos\n",
    "Realizar una funcion que reciba el corpus y el índice de un documento y devuelva los documentos ordenados por la similitud coseno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.20034190268098703, 1: 1.0, 2: 0.10845711727883083}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 0, 2]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import operator\n",
    "\n",
    "def similitud(docus, index, vocab):\n",
    "    \n",
    "    tf_idf = TF_IDF(docus, vocab)\n",
    "    \n",
    "    similitudes = {i:cosine_similarity(tf_idf[i], tf_idf[index]) for i in range(len(tf_idf))}\n",
    "    print(similitudes)\n",
    "    sort = dict(sorted(similitudes.items(), key=operator.itemgetter(1), reverse=True))\n",
    "    sim_sort = list(sort.keys())\n",
    "    \n",
    "    return sim_sort\n",
    "\n",
    "similitud(docu, 1, vocab)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO5fRYTpympAwJSVbric6dW",
   "collapsed_sections": [],
   "name": "1a - word2vec.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
