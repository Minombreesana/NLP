{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kBLpTr7plguX"
   },
   "source": [
    "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
    "\n",
    "\n",
    "# Procesamiento de lenguaje natural\n",
    "## Sentiment analysis con Embeddings + LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9W6nuajhlqZD"
   },
   "source": [
    "### Objetivo\n",
    "El objetivo es utilizar las críticas de compradores de ropa para que el sistema determine la evaluación del comprador y su crítica (cuantas estrellas le asigna al producto)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i6zvzv3qZ6xS"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade --no-cache-dir gdown --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hCpOVzJdl8_p"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import io\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8UPeRkrAmbF3"
   },
   "source": [
    "### Datos\n",
    "Utilizaremos como dataset críticas de compradores de ropa (eCommerce) los cuales puntuaron a cada prenda con un puntaje de 1 a 5 estrellas.\\\n",
    "Referencia del dataset: [LINK](https://www.kaggle.com/nicapotato/womens-ecommerce-clothing-reviews/version/1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C7jLvTU3lSyL"
   },
   "outputs": [],
   "source": [
    "# Descargar la carpeta de dataset\n",
    "import os\n",
    "import gdown\n",
    "if os.access('clothing_ecommerce_reviews.csv', os.F_OK) is False:\n",
    "    url = 'https://drive.google.com/uc?id=1k2Dz4oY5uxI3JEaT6m-L2T2HvLkECYIP'\n",
    "    output = 'clothing_ecommerce_reviews.csv'\n",
    "    gdown.download(url, output, quiet=False)\n",
    "else:\n",
    "    print(\"El dataset ya se encuentra descargado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o-SV1P3dnD1J"
   },
   "outputs": [],
   "source": [
    "# Armar el dataset\n",
    "df = pd.read_csv('clothing_ecommerce_reviews.csv')\n",
    "df.drop(columns = ['Unnamed: 0'], inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q-OwSePKm-FK"
   },
   "source": [
    "### 1 - Limpieza de datos\n",
    "Alumno:\n",
    "- Del dataset unicamente utilizar las columnas \"Review Text\" y \"Rating.\n",
    "- Tranformar el rating 1-5 a una escala numérica de 0 a 4.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-hc7-AmYnPC3"
   },
   "outputs": [],
   "source": [
    "df_reviews = df.loc[:, ['Review Text', 'Rating']].dropna()\n",
    "df_reviews['Rating'] = df_reviews['Rating'] - 1\n",
    "df_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sZtvASVOn3ty"
   },
   "outputs": [],
   "source": [
    "# Alumno: Observar como está distribuido el dataset respecto a la columna Rating\n",
    "# es decir, observar que tan balanceado se encuentra respecot a cada clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gVJ_RVi4o1h3"
   },
   "outputs": [],
   "source": [
    "# Alumno: tomar la columna de las review y almacenarlo todo en un vector numpy de reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4nT5Un_co65Q"
   },
   "outputs": [],
   "source": [
    "# Alumno: Cuantas reviews (rows) hay para evaluar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HP5uN9tqpHu_"
   },
   "outputs": [],
   "source": [
    "# Alumno: Concatenar todas las reviews para armar el corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FEzmePgdpf74"
   },
   "outputs": [],
   "source": [
    "# Alumno: ¿Cuál es la longitud de ese corpus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MYeJLdDmpvOe"
   },
   "outputs": [],
   "source": [
    "# Alumno: Utilizar \"text_to_word_sequence\" para separar las palabras en tokens\n",
    "# recordar que text_to_word_sequence automaticamente quita los signos de puntuacion y pasa el texto a lowercase\n",
    "from keras.preprocessing.text import text_to_word_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M6L-fnWAp_lA"
   },
   "outputs": [],
   "source": [
    "# Alumno: Dar un vistazo a los primeros 20 tokens/palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-8QgwwMUqG0d"
   },
   "outputs": [],
   "source": [
    "# Alumno: ¿Cuántos tokens/palabras hay?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TFukNZdOsZ8_"
   },
   "outputs": [],
   "source": [
    "# Alumno: Tokenizar las palabras con el Tokenizer de Keras\n",
    "# Definir una máxima cantidad de palabras a utilizar:\n",
    "# num_words --> the maximum number of words to keep, based on word frequency.\n",
    "# Only the most common num_words-1 words will be kept.\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "num_words = 2000\n",
    "vocab_size = num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JnR1tlqZy94X"
   },
   "outputs": [],
   "source": [
    "# Alumno: Obtener el diccionario de palabra (word) a índice\n",
    "# y observar la cantidad total del vocabulario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AvWzzSretQXf"
   },
   "outputs": [],
   "source": [
    "# Alumno: Convertir las palabras/tokens a números"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "za73M5SRtbrP"
   },
   "outputs": [],
   "source": [
    "# Alumno: Determinar cual es la oración más larga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oCkO9Wc9tls1"
   },
   "outputs": [],
   "source": [
    "# Alumno: Realizar padding de las sentencias al mismo tamaño\n",
    "# tomando de referencia la máxima sentencia\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "maxlen = 115"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kGHHabVdt_aa"
   },
   "outputs": [],
   "source": [
    "# Alumno: Observar las dimensiones de la variable input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "llVM-tzQo9_F"
   },
   "outputs": [],
   "source": [
    "# Alumno tomar la columna rating y alcemacenarla en una variable \"y\" transformada a oneHotEncoding\n",
    "# Su shape debe ser equivalente la cantidad de rows del corpus y a la cantidad\n",
    "# de clases que se deseen predecir (en este ejemplo son 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rmz9A6n4uK4V"
   },
   "outputs": [],
   "source": [
    "# Alumno: Dividir los datos en train y test\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EcDPlhEouQ9E"
   },
   "outputs": [],
   "source": [
    "# Alumno: determinar la dimensiones de entrada y salida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NpbQHExL6OTu"
   },
   "source": [
    "### 2 - Entrenar el modelo con Embeddings + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NUkuWBsM6cx3"
   },
   "outputs": [],
   "source": [
    "# Alumno: Entrene su modelo con LSTM entrenando sus propios embeddings\n",
    "# o utilizando embeddings pre-entrenados.\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dropout"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPDU98WqI1eIPhnZ3eGFqqe",
   "collapsed_sections": [],
   "name": "5d - clothing_ecommerce_reviews.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
